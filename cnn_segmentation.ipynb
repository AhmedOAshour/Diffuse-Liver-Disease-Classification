{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4552c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7760b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder = \"dataset\",\n",
    "                classes = [\n",
    "                            \"normal\",\n",
    "                            \"fatty\",\n",
    "                            \"cirrhosis\"\n",
    "                        ]):\n",
    "    image_names = {}\n",
    "    images = []\n",
    "    # Get all image names in folders\n",
    "    for cls in classes:\n",
    "        image_names[cls] = os.listdir(f'{folder}/{cls}')\n",
    "        \n",
    "    # read all images to list\n",
    "    for cls in classes:\n",
    "        for name in image_names[cls]:\n",
    "            img = cv2.imread(f'{folder}/{cls}/{name}', cv2.IMREAD_GRAYSCALE)\n",
    "#             img = sitk.ReadImage(f'{folder}/{cls}/{name}', sitk.sitkUInt8)\n",
    "#             mask_name = name.split('.')[0]+\"_label_ground-truth_coco-panoptic.png\"\n",
    "            mask_name = name.split('.')[0]+\"_label_ground-truth_semantic.png\"\n",
    "            mask = cv2.imread(f'{folder}/instance_mask/{mask_name}', cv2.IMREAD_GRAYSCALE)\n",
    "#             mask = sitk.ReadImage(f'instance_mask/{mask_name}', sitk.sitkUInt8)\n",
    "            images.append((name, img, cls, mask))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9faa0e3",
   "metadata": {},
   "source": [
    "# Padding Images"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47cfaea1",
   "metadata": {},
   "source": [
    "# image sizes\n",
    "xs = []\n",
    "ys = []\n",
    "for name, img, cls, mask in images:\n",
    "    x,y = sitk.GetArrayFromImage(img).shape\n",
    "    xs.append(x)\n",
    "    ys.append(y)\n",
    "xu = np.unique(xs)\n",
    "yu = np.unique(ys)\n",
    "print(\"min x: \", min(xu))\n",
    "print(\"max x: \", max(xu))\n",
    "\n",
    "print(\"\\nmin y: \", min(yu))\n",
    "print(\"max y: \", max(yu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(img, mask, x=512, y=512):\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    mask = sitk.GetArrayFromImage(mask)\n",
    "    \n",
    "    pad_img = np.zeros((x,y))\n",
    "    pad_mask = np.zeros((x,y))\n",
    "    \n",
    "    pad_img[:img.shape[0],:img.shape[1]] = img\n",
    "    pad_mask[:mask.shape[0],:mask.shape[1]] = mask\n",
    "    \n",
    "#     pad_img = sitk.GetImageFromArray(pad_img)\n",
    "#     pad_mask = sitk.GetImageFromArray(pad_mask)\n",
    "    \n",
    "    return pad_img, pad_mask"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b59c1ba",
   "metadata": {},
   "source": [
    "for name, img, cls, mask in images:\n",
    "    i , m = padding(img, mask)\n",
    "    cv2.imwrite(f'padded dataset/{cls}/{name}', i)\n",
    "    cv2.imwrite('padded dataset/masks/'+name.split('.')[0]+'_label_ground-truth_semantic.png', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0445a",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e39f079",
   "metadata": {},
   "source": [
    "images = read_images('padded dataset')\n",
    "data = pd.DataFrame(columns=[\"imgs\",'masks'])\n",
    "\n",
    "imgs = []\n",
    "masks = []\n",
    "for name, img, cls, mask in images:\n",
    "    imgs.append(img)\n",
    "    masks.append(mask)\n",
    "\n",
    "data['imgs'] = imgs\n",
    "data['masks'] = masks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "598bc3f0",
   "metadata": {},
   "source": [
    "images = read_images('padded dataset')\n",
    "imgs = []\n",
    "masks = []\n",
    "count = 0\n",
    "\n",
    "for name, img, cls, mask in images:\n",
    "    imgs.append(cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_CUBIC).reshape(256,256,1))\n",
    "    masks.append(cv2.resize(mask, dsize=(256, 256), interpolation=cv2.INTER_CUBIC).reshape(256,256,1))\n",
    "    count+=1\n",
    "#     if count == 300:\n",
    "#         train = (imgs, masks)\n",
    "#         imgs = []\n",
    "#         masks = []\n",
    "    if count == 350:\n",
    "        train = np.asarray([np.asarray(imgs), np.asarray(masks)])\n",
    "        imgs = []\n",
    "        masks = []\n",
    "# valid = (imgs, masks)\n",
    "test = np.asarray([np.asarray(imgs), np.asarray(masks)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f3f945d",
   "metadata": {},
   "source": [
    "def data_gen(data):\n",
    "    for x,y in zip(data[0],data[1]):\n",
    "        yield (x,y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24c948c6",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, concatenate\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def unet(input_size = (256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "#     model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d69bd632",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# train_gen = data_gen(train)\n",
    "# valid_gen = data_gen(valid)\n",
    "# test_gen = data_gen(test)\n",
    "model = unet()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e93a7dd",
   "metadata": {},
   "source": [
    "train[0].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1741c51",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "imgs = train[0]\n",
    "masks = train[1]\n",
    "model.compile(optimizer='rmsprop', loss=\"binary_crossentropy\")\n",
    "model.fit(imgs, masks, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0850f85",
   "metadata": {},
   "source": [
    "test_imgs = test[0]\n",
    "test_masks = test[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a12dd737",
   "metadata": {},
   "source": [
    "preds = model.predict(test_imgs)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c422b96",
   "metadata": {},
   "source": [
    "preds[0].shape\n",
    "plt.imshow(preds[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c2eff",
   "metadata": {},
   "source": [
    "# Detectron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549363cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.checkpoint import Checkpointer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances, load_coco_json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pycocotools import mask\n",
    "\n",
    "from segments.utils import export_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69f982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml'))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.WEIGHTS = 'model_final.pth'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eb3eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, predictor):\n",
    "        self.predictor = predictor\n",
    "\n",
    "    def _convert_to_segments_format(self, image, outputs):\n",
    "        # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
    "        segmentation_bitmap = np.zeros((image.shape[0], image.shape[1]), np.uint32)\n",
    "        annotations = []\n",
    "        counter = 1\n",
    "        instances = outputs['instances']\n",
    "        for i in range(len(instances.pred_classes)):\n",
    "            category_id = int(instances.pred_classes[i])\n",
    "            instance_id = counter\n",
    "            mask = instances.pred_masks[i].cpu()\n",
    "            segmentation_bitmap[mask] = instance_id\n",
    "            annotations.append({'id': instance_id, 'category_id': category_id})\n",
    "            counter += 1\n",
    "        return segmentation_bitmap, annotations\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        outputs = self.predictor(image)\n",
    "        label, label_data = self._convert_to_segments_format(image, outputs)\n",
    "\n",
    "        return label, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "780f4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = Model(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f060d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "images = read_images()\n",
    "imgs = []\n",
    "masks = []\n",
    "count = 0\n",
    "\n",
    "for name, img, cls, mask in images:\n",
    "    imgs.append(img)\n",
    "    masks.append(mask)\n",
    "    count+=1\n",
    "#     if count == 300:\n",
    "#         train = (imgs, masks)\n",
    "#         imgs = []\n",
    "#         masks = []\n",
    "    if count == 350:\n",
    "        train = np.asarray([np.asarray(imgs), np.asarray(masks)])\n",
    "        imgs = []\n",
    "        masks = []\n",
    "# valid = (imgs, masks)\n",
    "test = np.asarray([np.asarray(imgs), np.asarray(masks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a166388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 716)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f990581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch\\functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "segmentation_bitmap, annotations = model(test[0][0].reshape(537,716,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60634846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"img.png\",segmentation_bitmap.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(segmentation_bitmap.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f753e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_bitmap.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf26d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
