{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1a5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aca7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_data, drop):\n",
    "    X_train = data.copy()\n",
    "    y_train = X_train.pop('target')\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "\n",
    "    X_train = X_train[y_train != drop]\n",
    "    X_test = X_test[y_test != drop]\n",
    "\n",
    "    y_train = y_train[y_train != drop]\n",
    "    y_test = y_test[y_test != drop]\n",
    "\n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train)\n",
    "    X_train = pd.DataFrame(std.transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "    X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    return X_train, y_train, X_test, y_test, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538703d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(model.predict(X_test),index=y_test.index)\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491a24f",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dbeec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset/train.csv', index_col='name')\n",
    "test_data = pd.read_csv('dataset/test.csv', index_col='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76717961",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "\n",
    "final = {}\n",
    "\n",
    "for drop in classes:\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop)\n",
    "    cls = np.unique(y_train)\n",
    "    selector = SelectKBest(score_func = f_classif, k = 108)\n",
    "    selector.fit(X_train, y_train)\n",
    "    results = pd.DataFrame(selector.scores_, index= X_train.columns, columns = [\"F_value\"])\\\n",
    "        .sort_values(\"F_value\",ascending = False)\n",
    "    final[f\"{cls[0]}_{cls[1]}\"]=results\n",
    "    results.to_csv(f\"dataset/fisher/{cls[0]}_{cls[1]}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e115e",
   "metadata": {},
   "source": [
    "## n Feature Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d55c30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  cirrhosis_fatty\n",
      "Random Forest\n",
      "ANN\n",
      "SVM\n",
      "Decision Tree\n",
      "KNN\n",
      "Classifier:  cirrhosis_normal\n",
      "Random Forest\n",
      "ANN\n",
      "SVM\n",
      "Decision Tree\n",
      "KNN\n",
      "Classifier:  fatty_normal\n",
      "Random Forest\n",
      "ANN\n",
      "SVM\n",
      "Decision Tree\n",
      "KNN\n",
      "Wall time: 14min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    max_features='auto',\n",
    "                    n_estimators= 500,\n",
    "                    max_depth=6,\n",
    "                    criterion='entropy',),\n",
    "    \"ANN\": MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=42),\n",
    "    \"SVM\": svm.SVC(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(\n",
    "                    random_state = 42,\n",
    "                    criterion = 'entropy',\n",
    "                    max_depth = 2,\n",
    "                    max_features = 'log2',\n",
    "                    splitter = 'best',),\n",
    "    \"KNN\": KNeighborsClassifier(\n",
    "                    algorithm='auto',\n",
    "                    leaf_size=30,\n",
    "                    metric='minkowski',\n",
    "                    metric_params=None,\n",
    "                    n_jobs=10,\n",
    "                    n_neighbors=2,\n",
    "                    p=3,\n",
    "                    weights='uniform'),\n",
    "}\n",
    "\n",
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "result = {col:pd.DataFrame() for col in final.keys()}\n",
    "\n",
    "for classifier in final.keys():\n",
    "    keep = classifier.split('_')\n",
    "    drop = [cls for cls in classes if cls not in keep]\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop[0])\n",
    "    print(\"Classifier: \", classifier)\n",
    "    for model_name in models.keys():\n",
    "        res = pd.DataFrame(columns=[model_name])\n",
    "        for i in range(2,108):\n",
    "            cols = final[classifier].index[0:i]\n",
    "            model, y_pred = train_test(models[model_name], X_train[cols], y_train, X_test[cols], y_test)\n",
    "            res.loc[i] = {model_name: accuracy_score(y_pred,y_test)}\n",
    "        print(model_name)\n",
    "        result[classifier] = pd.concat([result[classifier], res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d4546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in result.keys():\n",
    "    result[name].to_excel(f\"dataset/fisher/model acc/{name}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1795d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
