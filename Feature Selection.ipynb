{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6372cc11",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "## Importing Libraries and importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9911f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from skfeature.function.similarity_based import fisher_score\n",
    "%matplotlib inline\n",
    "\n",
    "#data = pd.read_csv('dataset/roi_95img_9_roi_glrlm_32p.csv')\n",
    "train = pd.read_csv('dataset/train.csv', index_col='name')\n",
    "\n",
    "X_train = train.copy()\n",
    "y_train = X_train.pop('target')\n",
    "\n",
    "# std = StandardScaler()\n",
    "# std.fit(X_train)\n",
    "# X_train = pd.DataFrame(std.transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd3a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns\n",
    "fishertrain = train.drop(cols[0],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee2a07",
   "metadata": {},
   "source": [
    "# Fisher's Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2864ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jundongl /scikit-feature\n",
    "# https://github.com/jundongl/scikit-feature/blob/master/skfeature/function/similarity_based/fisher_score.py\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "from skfeature.utility.construct_W import construct_W\n",
    "\n",
    "\n",
    "def fisher_score(X, y):\n",
    "    \"\"\"\n",
    "    This function implements the fisher score feature selection, steps are as follows:\n",
    "    1. Construct the affinity matrix W in fisher score way\n",
    "    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n",
    "    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n",
    "    4. Fisher score for the r-th feature is score = (fr_hat'*D*fr_hat)/(fr_hat'*L*fr_hat)-1\n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    y: {numpy array}, shape (n_samples,)\n",
    "        input class labels\n",
    "    Output\n",
    "    ------\n",
    "    score: {numpy array}, shape (n_features,)\n",
    "        fisher score for each feature\n",
    "    Reference\n",
    "    ---------\n",
    "    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
    "    Duda, Richard et al. \"Pattern classification.\" John Wiley & Sons, 2012.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct weight matrix W in a fisherScore way\n",
    "    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n",
    "    W = construct_W(X, **kwargs)\n",
    "\n",
    "    # build the diagonal D matrix from affinity matrix W\n",
    "    D = np.array(W.sum(axis=1))\n",
    "    L = W\n",
    "    tmp = np.dot(np.transpose(D), X)\n",
    "    D = diags(np.transpose(D), [0])\n",
    "    Xt = np.transpose(X)\n",
    "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
    "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
    "    # compute the numerator of Lr\n",
    "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # compute the denominator of Lr\n",
    "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # avoid the denominator of Lr to be 0\n",
    "    D_prime[D_prime < 1e-12] = 10000\n",
    "    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
    "\n",
    "    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n",
    "    score = 1.0/lap_score - 1\n",
    "    return np.transpose(score)\n",
    "\n",
    "\n",
    "def feature_ranking(score):\n",
    "    \"\"\"\n",
    "    Rank features in descending order according to fisher score, the larger the fisher score, the more important the\n",
    "    feature is\n",
    "    \"\"\"\n",
    "    idx = np.argsort(score, 0)\n",
    "    return idx[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a57150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1629677  0.15145961 0.04543857 0.00033435 0.00350496 0.00547253\n",
      " 0.03413415 0.00796525 0.03743359 0.0309354  0.02775301 0.16505651\n",
      " 0.02067744 0.03100367 0.01700868 0.00348917 0.03409946 0.03818261\n",
      " 0.03804336 0.01244174 0.03474307 0.00863173 0.00693588 0.02842413\n",
      " 0.03859532 0.0500406  0.02595757 0.02804907 0.01670018 0.02082355\n",
      " 0.00727578 0.01886575 0.03993788 0.01098105 0.03956955 0.02958682\n",
      " 0.16976166 0.02041941 0.17660214 0.12618536 0.01060717 0.02601432\n",
      " 0.16782004 0.00431786 0.03461986 0.00713245 0.03847083 0.0172369\n",
      " 0.0203581  0.02755897 0.01616643 0.08952557 0.0500406  0.02396635\n",
      " 0.00868475 0.0347061  0.02214598 0.00889591 0.04911281 0.04248406\n",
      " 0.01441701 0.02907835 0.05209696 0.04248406 0.01441701 0.02406681\n",
      " 0.05028331 0.02736035 0.01310276 0.01744439 0.03520606 0.01321904\n",
      " 0.00495139 0.01233064 0.04277581 0.01321904 0.00495139 0.00461782\n",
      " 0.04498306 0.01321169 0.00075252 0.00868099 0.0628596  0.03678111\n",
      " 0.03325879 0.03381046 0.04957073 0.03678111 0.03325879 0.03413019\n",
      " 0.04352383 0.03785592 0.03340012 0.03628849 0.04838353 0.08296074\n",
      " 0.05304844 0.03403837 0.04008418 0.0850583  0.05304844 0.03403837\n",
      " 0.05198667 0.08053805 0.06212482 0.04212475 0.05609869]\n"
     ]
    }
   ],
   "source": [
    "X = X_train.to_numpy()\n",
    "Y = y_train.to_numpy()\n",
    "\n",
    "score = fisher_score(X, Y)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d413f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38  36  42  11   0   1  39  51  99  95 103  82 104 106  96 100  62 102\n",
      "  66  25  52  86  58  94   2  78  90  74  59  63 105  98  32  34  24  46\n",
      "  17  18  91   8  87  83  93  70  20  55  44   6  89  16  97 101  85  92\n",
      "  88  84  13   9  35  61  23  27  10  49  67  41  26  65  53  56  29  12\n",
      "  37  48  31  69  47  14  28  50  60  64  75  71  79  68  19  73  33  40\n",
      "  57  54  81  21   7  30  45  22   5  76  72  77  43   4  15  80   3]\n"
     ]
    }
   ],
   "source": [
    "idx = feature_ranking(score)\n",
    "\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "836ffd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64.]\n",
      " [75.]\n",
      " [73.]\n",
      " ...\n",
      " [84.]\n",
      " [92.]\n",
      " [97.]]\n"
     ]
    }
   ],
   "source": [
    "num_fea = 1\n",
    "selected_features_train = X[:, idx[0:num_fea]]\n",
    "selected_features_test = X[:, idx[0:num_fea]]\n",
    "print(selected_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0231e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X_train.to_numpy()\n",
    "Y = y_train.to_numpy()\n",
    "\n",
    "\n",
    "ranks = fisher_score.fisher_score(X,Y,mode='index')\n",
    "\n",
    "#remove first 30 features\n",
    "dropped_columns = ranks[30:]\n",
    "cols = train.columns\n",
    "fishertrain = train.copy()\n",
    "for i in range(len(dropped_columns)):\n",
    "    fishertrain = fishertrain.drop(cols[dropped_columns[i]],axis = 1)\n",
    "\n",
    "# fishertrain.to_csv('dataset/fishertrain.csv',index= False)\n",
    "\n",
    "test = pd.read_csv('dataset/test.csv', index_col='name')\n",
    "cols = test.columns\n",
    "fishertest = test.copy()\n",
    "for i in range(len(dropped_columns)):\n",
    "    fishertest = fishertest.drop(cols[dropped_columns[i]],axis = 1)\n",
    "\n",
    "# fishertest.to_csv('dataset/fishertest.csv',index= False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6e81c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_importance = pd.Series(ranks,X_train.columns[0:len(X_train.columns)])\n",
    "plt.figure(figsize=(13, 13), dpi=80)\n",
    "plt.xlabel('Fisher\\'s Score', fontsize=40)\n",
    "feat_importance.plot(kind='barh',color='teal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29943d",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr, corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_train = train.copy()\n",
    "correlation_test = test.copy()\n",
    "corr_features, corr_matrix = correlation(correlation_train, 0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,100))\n",
    "sns.heatmap(corr_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4363312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_train = correlation_train.drop(corr_features,axis=1)\n",
    "correlation_test = correlation_test.drop(corr_features,axis=1)\n",
    "correlation_test.to_csv('dataset/corrtest.csv' ,index= False)    \n",
    "correlation_train.to_csv('dataset/corrtrain.csv',index= False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda4a4e",
   "metadata": {},
   "source": [
    "# Mutual Information Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    mi_scores = mutual_info_classif(X, y, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "    \n",
    "mi_scores = make_mi_scores(X_train, y_train)\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 15))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51938275",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6\n",
    "cols_to_remove = []\n",
    "for key in mi_scores.keys():\n",
    "    if mi_scores[key] < 0.6:\n",
    "        cols_to_remove.append(key)\n",
    "        \n",
    "mi_train = train.drop(columns=cols_to_remove)\n",
    "mi_test = test.drop(columns=cols_to_remove)\n",
    "mi_test.to_csv('dataset/mi_test.csv' ,index= False)    \n",
    "mi_train.to_csv('dataset/mi_train.csv',index= False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481f5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
