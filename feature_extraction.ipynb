{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5bb83d",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de7e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import greycomatrix\n",
    "from skimage.feature.texture import greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from radiomics import glrlm, glcm\n",
    "# import pyfeats\\\\\n",
    "import pandas as pd\n",
    "import multiprocessing as mlp\n",
    "import math\n",
    "import feature_extraction as fe\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dcb13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe50bfe",
   "metadata": {},
   "source": [
    "## Define Feature Extraction functions\n",
    "\n",
    "### Read dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder = \"dataset/train\",\n",
    "                classes = [\n",
    "                            \"normal\",\n",
    "                            \"fatty\",\n",
    "                            \"cirrhosis\"\n",
    "                        ]):\n",
    "    image_names = {}\n",
    "    images = []\n",
    "    # Get all image names in folders\n",
    "    for cls in classes:\n",
    "        image_names[cls] = os.listdir(f'{folder}/{cls}')\n",
    "\n",
    "    # read all images to list\n",
    "    for cls in classes:\n",
    "        for name in image_names[cls]:\n",
    "            mask = []\n",
    "            with open(f'dataset/masks/{name[0:-4]}.txt', 'r') as file:\n",
    "                data = file.read()\n",
    "                data = data.strip().split('\\n')\n",
    "                for line in data:\n",
    "                    x, y = line.split(',')\n",
    "                    mask.append((int(y),int(x)))\n",
    "            img = sitk.ReadImage(f'{folder}/{cls}/{name}', sitk.sitkUInt8)\n",
    "            images.append((name, img,cls,mask))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0a6a1",
   "metadata": {},
   "source": [
    "### Extract ROIs from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4160da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(img, start , size = (32,32)):\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    roi = img[start[0]:start[0]+size[0],start[1]:start[1]+size[1]]\n",
    "    mask = np.zeros(img.shape)\n",
    "    mask[start[0]:start[0]+size[0],start[1]:start[1]+size[1]] = 1\n",
    "    return roi, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73316262",
   "metadata": {},
   "source": [
    "# Calculate Liver Diagonal Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d7cf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(img, mask):\n",
    "    # top right, bottom left\n",
    "    tr_distance = []\n",
    "    bl_distance = []\n",
    "\n",
    "    # top left, bottom right\n",
    "    tl_distance = []\n",
    "    br_distance = []\n",
    "\n",
    "\n",
    "    for x,y in mask:\n",
    "        tr_distance.append(math.dist([0,img.shape[1]],[x+32,y]))\n",
    "        bl_distance.append(math.dist([img.shape[0],0],[x,y+32]))\n",
    "\n",
    "        tl_distance.append(math.dist([0,0],[x,y]))\n",
    "        br_distance.append(math.dist(img.shape,[x+32,y+32]))\n",
    "\n",
    "\n",
    "    top_right = mask[tr_distance.index(min(tr_distance))]\n",
    "    bottom_left = mask[bl_distance.index(min(bl_distance))]\n",
    "\n",
    "    top_left = mask[tl_distance.index(min(tl_distance))]\n",
    "    bottom_right = mask[br_distance.index(min(br_distance))]\n",
    "    \n",
    "    return max(math.dist(top_right,bottom_left),math.dist(top_left,bottom_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51daa8a",
   "metadata": {},
   "source": [
    "### Extract Features from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd4402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img, roi_pos):\n",
    "    roi_mask_arr = []\n",
    "    for pos in roi_pos:\n",
    "        roi_mask_arr.append(extract_roi(img, pos))\n",
    "\n",
    "    # 0 45 90 135 degrees\n",
    "    angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
    "\n",
    "    da_dict = {\n",
    "        0: \"d1_0\",1: \"d1_45\",2: \"d1_90\",3: \"d1_135\",\n",
    "        4: \"d2_0\",5: \"d2_45\",6: \"d2_90\",7: \"d2_135\",\n",
    "        8: \"d3_0\",9: \"d3_45\",10: \"d3_90\",11: \"d3_135\"\n",
    "    }\n",
    "\n",
    "    length = get_length(sitk.GetArrayFromImage(img), roi_pos)\n",
    "\n",
    "    feat_arr = []\n",
    "    for roi, mask in roi_mask_arr:\n",
    "        features = {}\n",
    "\n",
    "        glcm_mtx = greycomatrix(roi, distances = [1,2,3], angles = angles, levels = 256)\n",
    "        con = greycoprops(glcm_mtx, 'contrast').flatten()\n",
    "        hom = greycoprops(glcm_mtx, 'homogeneity').flatten()\n",
    "        en = greycoprops(glcm_mtx, 'energy').flatten()\n",
    "        corr = greycoprops(glcm_mtx, 'correlation').flatten()\n",
    "\n",
    "        for j in range(len(da_dict)):\n",
    "            features[f'contrast_{da_dict[j]}'] = con[j]\n",
    "            features[f'homogeneity_{da_dict[j]}'] = hom[j]\n",
    "            features[f'energy_{da_dict[j]}'] = en[j]\n",
    "            features[f'correlation_{da_dict[j]}'] = corr[j]\n",
    "\n",
    "        features[f'entropy'] = shannon_entropy(roi)\n",
    "\n",
    "        features['length'] = length\n",
    "\n",
    "        # pyradiomics\n",
    "        mask = sitk.GetImageFromArray(mask)\n",
    "        # First Order features\n",
    "        firstOrderFeatures = firstorder.RadiomicsFirstOrder(img, mask)\n",
    "        # firstOrderFeatures.enableFeatureByName('Mean', True)\n",
    "        firstOrderFeatures.enableAllFeatures()\n",
    "        results = firstOrderFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "\n",
    "        # GLCM features\n",
    "        glcmFeatures = glcm.RadiomicsGLCM(img, mask)\n",
    "        glcmFeatures.enableAllFeatures()\n",
    "        results = glcmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        #\n",
    "        # GLRLM features\n",
    "        glrlmFeatures = glrlm.RadiomicsGLRLM(img, mask)\n",
    "        glrlmFeatures.enableAllFeatures()\n",
    "        results = glrlmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "\n",
    "        feat_arr.append(features)\n",
    "\n",
    "    return feat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486a2d3",
   "metadata": {},
   "source": [
    "### Construct dataframe from ROI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a0f2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(images):\n",
    "    # dataframe consists of features of 1 ROI per image\n",
    "    # column name roiNum_feature\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for img, cls, mask in images:\n",
    "        feat_arr = feature_extraction(img, roi_pos=mask)\n",
    "        for row in feat_arr:\n",
    "            row['target'] = cls\n",
    "            data = data.append(row,ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c31aa7",
   "metadata": {},
   "source": [
    "### Construct dataframe using multiprocessing\n",
    "### Reduced runtime by 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f1592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_with_mlp(images, n=9): \n",
    "    pool = mlp.Pool(n)\n",
    "    results = pool.map(fe.build_dataframe,np.array_split(images,n))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639b10c",
   "metadata": {},
   "source": [
    "## Feature Analysis and Selection\n",
    "\n",
    "### Extract Features and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7f03422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d1_90</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>1.023900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.214386</td>\n",
       "      <td>70.884881</td>\n",
       "      <td>5.190461</td>\n",
       "      <td>27.420777</td>\n",
       "      <td>2.159861</td>\n",
       "      <td>1.169789</td>\n",
       "      <td>0.316116</td>\n",
       "      <td>0.520472</td>\n",
       "      <td>0.246282</td>\n",
       "      <td>7.505986e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177287</td>\n",
       "      <td>0.197639</td>\n",
       "      <td>0.162198</td>\n",
       "      <td>0.192916</td>\n",
       "      <td>0.140118</td>\n",
       "      <td>0.162515</td>\n",
       "      <td>0.137177</td>\n",
       "      <td>0.146077</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>294.342970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.953822</td>\n",
       "      <td>33.997997</td>\n",
       "      <td>4.488373</td>\n",
       "      <td>176.498185</td>\n",
       "      <td>12.593087</td>\n",
       "      <td>1.654653</td>\n",
       "      <td>0.331033</td>\n",
       "      <td>0.171877</td>\n",
       "      <td>0.128860</td>\n",
       "      <td>2.695262e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109722</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.118423</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.106142</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>0.101120</td>\n",
       "      <td>72.108890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.744314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.050039</td>\n",
       "      <td>0.042185</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>0.035083</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>135.764502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.729294</td>\n",
       "      <td>0.870617</td>\n",
       "      <td>-0.024615</td>\n",
       "      <td>0.534995</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.407430</td>\n",
       "      <td>0.163213</td>\n",
       "      <td>6.255283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117785</td>\n",
       "      <td>0.130055</td>\n",
       "      <td>0.109110</td>\n",
       "      <td>0.122657</td>\n",
       "      <td>0.093496</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>0.090946</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.089072</td>\n",
       "      <td>243.704739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>4.182663</td>\n",
       "      <td>2.084719</td>\n",
       "      <td>0.282485</td>\n",
       "      <td>0.807595</td>\n",
       "      <td>0.254504</td>\n",
       "      <td>0.513868</td>\n",
       "      <td>0.238976</td>\n",
       "      <td>7.787500e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154595</td>\n",
       "      <td>0.173784</td>\n",
       "      <td>0.141294</td>\n",
       "      <td>0.165697</td>\n",
       "      <td>0.117997</td>\n",
       "      <td>0.140509</td>\n",
       "      <td>0.115081</td>\n",
       "      <td>0.122553</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>286.216701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>6.122207</td>\n",
       "      <td>9.357921</td>\n",
       "      <td>0.876473</td>\n",
       "      <td>1.345874</td>\n",
       "      <td>0.373407</td>\n",
       "      <td>0.625236</td>\n",
       "      <td>0.323690</td>\n",
       "      <td>9.169306e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197679</td>\n",
       "      <td>0.226263</td>\n",
       "      <td>0.178031</td>\n",
       "      <td>0.223166</td>\n",
       "      <td>0.151147</td>\n",
       "      <td>0.180674</td>\n",
       "      <td>0.147460</td>\n",
       "      <td>0.161069</td>\n",
       "      <td>0.146184</td>\n",
       "      <td>340.164666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>66.896373</td>\n",
       "      <td>5954.836767</td>\n",
       "      <td>390.534435</td>\n",
       "      <td>39.317592</td>\n",
       "      <td>10.517470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.587563</td>\n",
       "      <td>1.962372e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count  10239.000000  10239.000000     10239.000000       10239.000000   \n",
       "mean      43.214386     70.884881         5.190461          27.420777   \n",
       "std       25.953822     33.997997         4.488373         176.498185   \n",
       "min        0.000000      0.000000         1.000000           0.000000   \n",
       "25%       24.000000     46.000000         2.729294           0.870617   \n",
       "50%       41.000000     69.000000         4.182663           2.084719   \n",
       "75%       60.000000     91.000000         6.122207           9.357921   \n",
       "max      174.000000    253.000000        66.896373        5954.836767   \n",
       "\n",
       "       ClusterShade  ClusterTendency      Contrast   Correlation  \\\n",
       "count  10239.000000     10239.000000  10239.000000  10239.000000   \n",
       "mean       2.159861         1.169789      0.316116      0.520472   \n",
       "std       12.593087         1.654653      0.331033      0.171877   \n",
       "min      -20.744314         0.000000      0.000000     -0.003308   \n",
       "25%       -0.024615         0.534995      0.170213      0.407430   \n",
       "50%        0.282485         0.807595      0.254504      0.513868   \n",
       "75%        0.876473         1.345874      0.373407      0.625236   \n",
       "max      390.534435        39.317592     10.517470      1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d1_90  \\\n",
       "count       10239.000000       1.023900e+04  ...       10239.000000   \n",
       "mean            0.246282       7.505986e-01  ...           0.177287   \n",
       "std             0.128860       2.695262e-01  ...           0.109722   \n",
       "min             0.000000      -3.203427e-16  ...           0.041775   \n",
       "25%             0.163213       6.255283e-01  ...           0.117785   \n",
       "50%             0.238976       7.787500e-01  ...           0.154595   \n",
       "75%             0.323690       9.169306e-01  ...           0.197679   \n",
       "max             1.587563       1.962372e+00  ...           1.000000   \n",
       "\n",
       "       homogeneity_d2_0  homogeneity_d2_135  homogeneity_d2_45  \\\n",
       "count      10239.000000        10239.000000       10239.000000   \n",
       "mean           0.197639            0.162198           0.192916   \n",
       "std            0.113970            0.104919           0.118423   \n",
       "min            0.050039            0.042185           0.043133   \n",
       "25%            0.130055            0.109110           0.122657   \n",
       "50%            0.173784            0.141294           0.165697   \n",
       "75%            0.226263            0.178031           0.223166   \n",
       "max            1.000000            1.000000           1.000000   \n",
       "\n",
       "       homogeneity_d2_90  homogeneity_d3_0  homogeneity_d3_135  \\\n",
       "count       10239.000000      10239.000000        10239.000000   \n",
       "mean            0.140118          0.162515            0.137177   \n",
       "std             0.101432          0.106142            0.100996   \n",
       "min             0.034135          0.039906            0.035083   \n",
       "25%             0.093496          0.106743            0.090946   \n",
       "50%             0.117997          0.140509            0.115081   \n",
       "75%             0.151147          0.180674            0.147460   \n",
       "max             1.000000          1.000000            1.000000   \n",
       "\n",
       "       homogeneity_d3_45  homogeneity_d3_90        length  \n",
       "count       10239.000000       10239.000000  10239.000000  \n",
       "mean            0.146077           0.135427    294.342970  \n",
       "std             0.104579           0.101120     72.108890  \n",
       "min             0.034000           0.027464    135.764502  \n",
       "25%             0.094952           0.089072    243.704739  \n",
       "50%             0.122553           0.112606    286.216701  \n",
       "75%             0.161069           0.146184    340.164666  \n",
       "max             1.000000           1.000000    480.000000  \n",
       "\n",
       "[8 rows x 108 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# images = read_images('dataset/train')\n",
    "# mlp_data = build_with_mlp(images)\n",
    "# data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     data = data.append(frame)\n",
    "\n",
    "# data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# data.to_csv(\"dataset/train.csv\")\n",
    "\n",
    "data = pd.read_excel('dataset/segment/train.xlsx', index_col='name')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cba1dff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.45 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d1_90</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2.543000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.901219</td>\n",
       "      <td>71.010814</td>\n",
       "      <td>5.015083</td>\n",
       "      <td>26.339400</td>\n",
       "      <td>2.002938</td>\n",
       "      <td>1.167737</td>\n",
       "      <td>0.314198</td>\n",
       "      <td>0.516472</td>\n",
       "      <td>0.250870</td>\n",
       "      <td>7.536736e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176278</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.161127</td>\n",
       "      <td>0.192916</td>\n",
       "      <td>0.140383</td>\n",
       "      <td>0.162683</td>\n",
       "      <td>0.138232</td>\n",
       "      <td>0.146238</td>\n",
       "      <td>0.136276</td>\n",
       "      <td>293.332709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.602086</td>\n",
       "      <td>35.537199</td>\n",
       "      <td>4.006853</td>\n",
       "      <td>201.157591</td>\n",
       "      <td>13.729393</td>\n",
       "      <td>1.703052</td>\n",
       "      <td>0.340934</td>\n",
       "      <td>0.170138</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>2.863724e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114381</td>\n",
       "      <td>0.116635</td>\n",
       "      <td>0.109106</td>\n",
       "      <td>0.123798</td>\n",
       "      <td>0.106084</td>\n",
       "      <td>0.108893</td>\n",
       "      <td>0.105759</td>\n",
       "      <td>0.109164</td>\n",
       "      <td>0.105858</td>\n",
       "      <td>66.869642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.731914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>0.047311</td>\n",
       "      <td>0.034038</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.032659</td>\n",
       "      <td>135.764502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.542497</td>\n",
       "      <td>0.861262</td>\n",
       "      <td>-0.008815</td>\n",
       "      <td>0.524250</td>\n",
       "      <td>0.168639</td>\n",
       "      <td>0.408831</td>\n",
       "      <td>0.161579</td>\n",
       "      <td>6.248237e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116269</td>\n",
       "      <td>0.130361</td>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.121239</td>\n",
       "      <td>0.091311</td>\n",
       "      <td>0.107111</td>\n",
       "      <td>0.090186</td>\n",
       "      <td>0.093158</td>\n",
       "      <td>0.087530</td>\n",
       "      <td>243.704739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.091035</td>\n",
       "      <td>1.934584</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>0.815074</td>\n",
       "      <td>0.251024</td>\n",
       "      <td>0.504155</td>\n",
       "      <td>0.241261</td>\n",
       "      <td>7.808226e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151490</td>\n",
       "      <td>0.172473</td>\n",
       "      <td>0.137961</td>\n",
       "      <td>0.161490</td>\n",
       "      <td>0.116903</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.121216</td>\n",
       "      <td>0.113159</td>\n",
       "      <td>295.025423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>6.060370</td>\n",
       "      <td>8.418262</td>\n",
       "      <td>0.766716</td>\n",
       "      <td>1.332241</td>\n",
       "      <td>0.380118</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>0.331848</td>\n",
       "      <td>9.225272e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193826</td>\n",
       "      <td>0.228049</td>\n",
       "      <td>0.175607</td>\n",
       "      <td>0.219497</td>\n",
       "      <td>0.150460</td>\n",
       "      <td>0.182794</td>\n",
       "      <td>0.149007</td>\n",
       "      <td>0.159531</td>\n",
       "      <td>0.147083</td>\n",
       "      <td>329.460165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>40.840677</td>\n",
       "      <td>5220.689962</td>\n",
       "      <td>333.676485</td>\n",
       "      <td>31.207490</td>\n",
       "      <td>9.178053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.135032</td>\n",
       "      <td>1.526040e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>435.247056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count   2543.000000   2543.000000      2543.000000        2543.000000   \n",
       "mean      42.901219     71.010814         5.015083          26.339400   \n",
       "std       26.602086     35.537199         4.006853         201.157591   \n",
       "min        0.000000      0.000000         1.000000           0.000000   \n",
       "25%       24.000000     45.000000         2.542497           0.861262   \n",
       "50%       41.000000     68.000000         4.091035           1.934584   \n",
       "75%       62.000000     93.000000         6.060370           8.418262   \n",
       "max      135.000000    253.000000        40.840677        5220.689962   \n",
       "\n",
       "       ClusterShade  ClusterTendency     Contrast  Correlation  \\\n",
       "count   2543.000000      2543.000000  2543.000000  2543.000000   \n",
       "mean       2.002938         1.167737     0.314198     0.516472   \n",
       "std       13.729393         1.703052     0.340934     0.170138   \n",
       "min      -13.731914         0.000000     0.000000    -0.003336   \n",
       "25%       -0.008815         0.524250     0.168639     0.408831   \n",
       "50%        0.275089         0.815074     0.251024     0.504155   \n",
       "75%        0.766716         1.332241     0.380118     0.618500   \n",
       "max      333.676485        31.207490     9.178053     1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d1_90  \\\n",
       "count        2543.000000       2.543000e+03  ...        2543.000000   \n",
       "mean            0.250870       7.536736e-01  ...           0.176278   \n",
       "std             0.138701       2.863724e-01  ...           0.114381   \n",
       "min             0.000000      -3.203427e-16  ...           0.046256   \n",
       "25%             0.161579       6.248237e-01  ...           0.116269   \n",
       "50%             0.241261       7.808226e-01  ...           0.151490   \n",
       "75%             0.331848       9.225272e-01  ...           0.193826   \n",
       "max             1.135032       1.526040e+00  ...           1.000000   \n",
       "\n",
       "       homogeneity_d2_0  homogeneity_d2_135  homogeneity_d2_45  \\\n",
       "count       2543.000000         2543.000000        2543.000000   \n",
       "mean           0.197346            0.161127           0.192916   \n",
       "std            0.116635            0.109106           0.123798   \n",
       "min            0.049470            0.038131           0.047311   \n",
       "25%            0.130361            0.108888           0.121239   \n",
       "50%            0.172473            0.137961           0.161490   \n",
       "75%            0.228049            0.175607           0.219497   \n",
       "max            1.000000            1.000000           1.000000   \n",
       "\n",
       "       homogeneity_d2_90  homogeneity_d3_0  homogeneity_d3_135  \\\n",
       "count        2543.000000       2543.000000         2543.000000   \n",
       "mean            0.140383          0.162683            0.138232   \n",
       "std             0.106084          0.108893            0.105759   \n",
       "min             0.034038          0.039583            0.034590   \n",
       "25%             0.091311          0.107111            0.090186   \n",
       "50%             0.116903          0.139648            0.114804   \n",
       "75%             0.150460          0.182794            0.149007   \n",
       "max             1.000000          1.000000            1.000000   \n",
       "\n",
       "       homogeneity_d3_45  homogeneity_d3_90       length  \n",
       "count        2543.000000        2543.000000  2543.000000  \n",
       "mean            0.146238           0.136276   293.332709  \n",
       "std             0.109164           0.105858    66.869642  \n",
       "min             0.035135           0.032659   135.764502  \n",
       "25%             0.093158           0.087530   243.704739  \n",
       "50%             0.121216           0.113159   295.025423  \n",
       "75%             0.159531           0.147083   329.460165  \n",
       "max             1.000000           1.000000   435.247056  \n",
       "\n",
       "[8 rows x 108 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# test_images = read_images(\"dataset/test\")\n",
    "# mlp_data = build_with_mlp(test_images)\n",
    "# test_data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     test_data = test_data.append(frame)\n",
    "    \n",
    "# test_data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# test_data.to_csv(\"dataset/test.csv\")\n",
    "\n",
    "test_data = pd.read_excel('dataset/segment/test.xlsx', index_col='name')\n",
    "\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fab083",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af4b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_data, drop=None, cols = None):\n",
    "    X_train = data.copy()\n",
    "    y_train = X_train.pop('target')\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "\n",
    "    if drop != None:\n",
    "        X_train = X_train[y_train != drop]\n",
    "        X_test = X_test[y_test != drop]\n",
    "\n",
    "        y_train = y_train[y_train != drop]\n",
    "        y_test = y_test[y_test != drop]\n",
    "    \n",
    "    if cols is None: cols = X_train.columns\n",
    "    \n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train[cols])\n",
    "    X_train = pd.DataFrame(std.transform(X_train[cols]), columns = cols, index = X_train.index)\n",
    "    X_test = pd.DataFrame(std.transform(X_test[cols]), columns = cols, index = X_test.index)\n",
    "    return X_train, y_train, X_test, y_test, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de6d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "    sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(model.predict(X_test),index=y_test.index)\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "261fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_pred(y_pred):\n",
    "    count = 0\n",
    "    prediction = {}\n",
    "    for name in np.unique(y_pred.index):\n",
    "        pred_cls = {}\n",
    "        for i in y_pred[name]:\n",
    "            if i not in pred_cls.keys():\n",
    "                pred_cls[i]=1\n",
    "            else: pred_cls[i]+=1\n",
    "        \n",
    "        prediction[name] = max(pred_cls, key=pred_cls.get)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93aedb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_acc(y_test, y_pred):\n",
    "    pred_count = 0\n",
    "    for key in y_pred.keys():\n",
    "        if y_test[key][0] == y_pred[key]:\n",
    "            pred_count += 1\n",
    "    return pred_count/len(y_pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "653fa695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatty cirrhosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC  Image Accuracy:  0.8461538461538461\n",
      "              precision    recall  f1-score      support\n",
      "cirrhosis      0.414219  0.595556  0.488605   450.000000\n",
      "fatty          0.868116  0.759670  0.810281  1577.000000\n",
      "accuracy       0.723236  0.723236  0.723236     0.723236\n",
      "macro avg      0.641168  0.677613  0.649443  2027.000000\n",
      "weighted avg   0.767350  0.723236  0.738868  2027.000000\n",
      "MLP  Image Accuracy:  0.8461538461538461\n",
      "              precision    recall  f1-score      support\n",
      "cirrhosis      0.453815  0.502222  0.476793   450.000000\n",
      "fatty          0.853499  0.827521  0.840309  1577.000000\n",
      "accuracy       0.755303  0.755303  0.755303     0.755303\n",
      "macro avg      0.653657  0.664871  0.658551  2027.000000\n",
      "weighted avg   0.764768  0.755303  0.759607  2027.000000\n",
      "SVC  Image Accuracy:  0.8461538461538461\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.430723  0.635556  0.513465   450.00000\n",
      "fatty          0.879677  0.760304  0.815646  1577.00000\n",
      "accuracy       0.732610  0.732610  0.732610     0.73261\n",
      "macro avg      0.655200  0.697930  0.664556  2027.00000\n",
      "weighted avg   0.780008  0.732610  0.748561  2027.00000\n",
      "\n",
      "\n",
      "\n",
      "normal cirrhosis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC  Image Accuracy:  0.6785714285714286\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.677165  0.573333  0.620939  450.000000\n",
      "normal         0.671795  0.761628  0.713896  516.000000\n",
      "accuracy       0.673913  0.673913  0.673913    0.673913\n",
      "macro avg      0.674480  0.667481  0.667418  966.000000\n",
      "weighted avg   0.674297  0.673913  0.670593  966.000000\n",
      "MLP  Image Accuracy:  0.5357142857142857\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.568365  0.471111  0.515188  450.000000\n",
      "normal         0.598651  0.687984  0.640216  516.000000\n",
      "accuracy       0.586957  0.586957  0.586957    0.586957\n",
      "macro avg      0.583508  0.579548  0.577702  966.000000\n",
      "weighted avg   0.584542  0.586957  0.581974  966.000000\n",
      "SVC  Image Accuracy:  0.6071428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.616307  0.571111  0.592849  450.000000\n",
      "normal         0.648452  0.689922  0.668545  516.000000\n",
      "accuracy       0.634576  0.634576  0.634576    0.634576\n",
      "macro avg      0.632379  0.630517  0.630697  966.000000\n",
      "weighted avg   0.633477  0.634576  0.633283  966.000000\n",
      "\n",
      "\n",
      "\n",
      "normal fatty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC  Image Accuracy:  0.8507462686567164\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.899475  0.760304  0.824055  1577.000000\n",
      "normal         0.502632  0.740310  0.598746   516.000000\n",
      "accuracy       0.755375  0.755375  0.755375     0.755375\n",
      "macro avg      0.701053  0.750307  0.711401  2093.000000\n",
      "weighted avg   0.801639  0.755375  0.768508  2093.000000\n",
      "MLP  Image Accuracy:  0.8208955223880597\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.866757  0.808497  0.836614  1577.000000\n",
      "normal         0.514469  0.620155  0.562390   516.000000\n",
      "accuracy       0.762064  0.762064  0.762064     0.762064\n",
      "macro avg      0.690613  0.714326  0.699502  2093.000000\n",
      "weighted avg   0.779906  0.762064  0.769008  2093.000000\n",
      "SVC  Image Accuracy:  0.8059701492537313\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.876664  0.793278  0.832889  1577.000000\n",
      "normal         0.510511  0.658915  0.575296   516.000000\n",
      "accuracy       0.760153  0.760153  0.760153     0.760153\n",
      "macro avg      0.693587  0.726097  0.704093  2093.000000\n",
      "weighted avg   0.786394  0.760153  0.769383  2093.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RFC\": RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    max_features='auto',\n",
    "                    n_estimators= 500,\n",
    "                    max_depth=6,\n",
    "                    criterion='entropy'),\n",
    "    \"MLP\": MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=42),\n",
    "    \"SVC\": svm.SVC(random_state=42)\n",
    "}\n",
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "\n",
    "for drop in classes:\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop)\n",
    "    print(*[cls for cls in classes if cls != drop])\n",
    "    for name in models.keys():\n",
    "        model, y_pred = train_test(models[name], X_train, y_train, X_test, y_test)\n",
    "        prediction = images_pred(y_pred)\n",
    "        print(name,\" Image Accuracy: \", images_acc(y_test, prediction))\n",
    "        report = classification_report(y_test, y_pred, output_dict = True)\n",
    "        cr = pd.DataFrame(report).transpose()\n",
    "        print(cr)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38fb4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat importance\n",
    "files = ['fatty_normal', 'cirrhosis_fatty', 'cirrhosis_normal']\n",
    "features_acc={}\n",
    "for name in files:\n",
    "    features_acc[name] = pd.read_csv(f'dataset/segment/manual selection/{name}.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b60ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Fatty MLP Image Accuracy:  0.8059701492537313\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.848315  0.766011  0.805065  1577.000000\n",
      "normal         0.448430  0.581395  0.506329   516.000000\n",
      "accuracy       0.720497  0.720497  0.720497     0.720497\n",
      "macro avg      0.648373  0.673703  0.655697  2093.000000\n",
      "weighted avg   0.749729  0.720497  0.731416  2093.000000\n"
     ]
    }
   ],
   "source": [
    "normal_fatty_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=31\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['fatty_normal']['ANN Accuracy'].sort_values(ascending=False)\n",
    "normal_fatty_cols = feat_imp.index[0:19]\n",
    "\n",
    "X_train, y_train, X_test, y_test, normal_fatty_std = split(data, test_data, 'cirrhosis', cols = normal_fatty_cols)\n",
    "model, y_pred = train_test(normal_fatty_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_fatty_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30cbeaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal/cirrhosis MLP Image Accuracy:  0.7142857142857143\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.590818  0.657778  0.622503  450.000000\n",
      "normal         0.668817  0.602713  0.634047  516.000000\n",
      "accuracy       0.628364  0.628364  0.628364    0.628364\n",
      "macro avg      0.629818  0.630245  0.628275  966.000000\n",
      "weighted avg   0.632482  0.628364  0.628669  966.000000\n"
     ]
    }
   ],
   "source": [
    "normal_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=81\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['cirrhosis_normal']['ANN Accuracy'].sort_values(ascending=False)\n",
    "normal_cirrhosis_cols = feat_imp.index[0:21].insert(0,'length')\n",
    "X_train, y_train, X_test, y_test, normal_cirrhosis_std = split(data, test_data, 'fatty', cols = normal_cirrhosis_cols)\n",
    "model, y_pred = train_test(normal_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"normal/cirrhosis MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b67e2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cirrhosis/Fatty MLP Image Accuracy:  0.8307692307692308\n",
      "              precision    recall  f1-score      support\n",
      "cirrhosis      0.500000  0.420000  0.456522   450.000000\n",
      "fatty          0.841722  0.880152  0.860508  1577.000000\n",
      "accuracy       0.777997  0.777997  0.777997     0.777997\n",
      "macro avg      0.670861  0.650076  0.658515  2027.000000\n",
      "weighted avg   0.765859  0.777997  0.770822  2027.000000\n"
     ]
    }
   ],
   "source": [
    "fatty_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=53\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['cirrhosis_fatty']['ANN Accuracy'].sort_values(ascending=False)\n",
    "fatty_cirrhosis_cols = feat_imp.index[0:63].insert(0,'length')\n",
    "\n",
    "X_train, y_train, X_test, y_test, fatty_cirrhosis_std = split(data, test_data, 'normal', cols = fatty_cirrhosis_cols)\n",
    "model, y_pred = train_test(fatty_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "fatty_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "341e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"normal_fatty\": (normal_fatty_mlp, normal_fatty_std, normal_fatty_cols),\n",
    "    \"normal_cirrhosis\": (normal_cirrhosis_mlp, normal_cirrhosis_std, normal_cirrhosis_cols),\n",
    "    \"fatty_cirrhosis\": (fatty_cirrhosis_mlp, fatty_cirrhosis_std, fatty_cirrhosis_cols)\n",
    "}\n",
    "\n",
    "X_test = test_data.copy()\n",
    "y_test = X_test.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52782718",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for name in models.keys():\n",
    "    cols = models[name][2]\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "    X_test = pd.DataFrame(models[name][1].transform(X_test[cols]), columns = cols, index = X_test.index)\n",
    "    X_test =  X_test[cols]\n",
    "    y_pred = pd.Series(models[name][0].predict(X_test),index=y_test.index)\n",
    "    predictions[name] = images_pred(y_pred)\n",
    "    \n",
    "image_names = np.unique(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebd475fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = np.unique(y_test.index)\n",
    "final_pred = {}\n",
    "for image in image_name:\n",
    "    pred = {\n",
    "        'normal': 0,\n",
    "        'fatty': 0,\n",
    "        'cirrhosis': 0\n",
    "    }\n",
    "    for model in predictions.keys():\n",
    "        pred[predictions[model][image]] += 1\n",
    "    cls = max(pred, key=pred.get)\n",
    "    if pred[cls] == 1:\n",
    "        final_pred[image] = 'abstain'\n",
    "    else: final_pred[image] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2387b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6625"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_acc(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "424c72bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "cirrhosis      0.375000  0.250000  0.300000  12.000000\n",
      "fatty          0.785714  0.862745  0.822430  51.000000\n",
      "normal         0.461538  0.428571  0.444444  14.000000\n",
      "accuracy       0.688312  0.688312  0.688312   0.688312\n",
      "macro avg      0.540751  0.513772  0.522291  77.000000\n",
      "weighted avg   0.662766  0.688312  0.672288  77.000000\n",
      "Abstention Rate:  0.0375\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test[~y_test.index.duplicated(keep='first')].sort_index()\n",
    "y_pred = pd.Series(final_pred).sort_index()\n",
    "abstain = y_pred[y_pred=='abstain'].index\n",
    "\n",
    "y_test = y_test.drop(abstain)\n",
    "y_pred = y_pred.drop(abstain)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)\n",
    "print(\"Abstention Rate: \", len(abstain)/(len(y_pred)+len(abstain)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2e47e3d",
   "metadata": {},
   "source": [
    "features_acc = pd.read_excel('dataset/manual selection/multiclass/multiclass.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c15c7f6",
   "metadata": {},
   "source": [
    "features_acc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be7e5226",
   "metadata": {},
   "source": [
    "multiclass_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=42\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['ANN Accuracy'].sort_values(ascending=False)\n",
    "multiclass_cols = feat_imp.index[0:97].insert(0,'length')\n",
    "\n",
    "X_train, y_train, X_test, y_test, multiclass_std = split(data, test_data, cols = multiclass_cols)\n",
    "model, y_pred = train_test(multiclass_mlp, X_train, y_train, X_test, y_test)\n",
    "multiclass_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c178100e",
   "metadata": {},
   "source": [
    "from joblib import dump\n",
    "\n",
    "for name in models.keys():\n",
    "    dump(models[name][0], f'dataset/models/{name}_mlp.joblib') \n",
    "    dump(models[name][1], f'dataset/models/{name}_std.joblib') \n",
    "    dump(models[name][2], f'dataset/models/{name}_cols.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
