{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5bb83d",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de7e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import greycomatrix\n",
    "from skimage.feature.texture import greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from radiomics import glrlm, glcm\n",
    "# import pyfeats\n",
    "import pandas as pd\n",
    "import multiprocessing as mlp\n",
    "import math\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcb13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe50bfe",
   "metadata": {},
   "source": [
    "## Define Feature Extraction functions\n",
    "\n",
    "### Read dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder = \"dataset/train\",\n",
    "                classes = [\n",
    "                            \"normal\",\n",
    "                            \"fatty\",\n",
    "                            \"cirrhosis\"\n",
    "                        ]):\n",
    "    image_names = {}\n",
    "    images = []\n",
    "    # Get all image names in folders\n",
    "    for cls in classes:\n",
    "        image_names[cls] = os.listdir(f'{folder}/{cls}')\n",
    "\n",
    "    # read all images to list\n",
    "    for cls in classes:\n",
    "        for name in image_names[cls]:\n",
    "            mask = []\n",
    "            with open(f'dataset/masks/{name[0:-4]}.txt', 'r') as file:\n",
    "                data = file.read()\n",
    "                data = data.strip().split('\\n')\n",
    "                for line in data:\n",
    "                    x, y = line.split(',')\n",
    "                    mask.append((int(y),int(x)))\n",
    "            img = sitk.ReadImage(f'{folder}/{cls}/{name}', sitk.sitkUInt8)\n",
    "            images.append((name, img,cls,mask))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0a6a1",
   "metadata": {},
   "source": [
    "### Extract ROIs from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4160da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(img, start , size = (32,32)):\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    roi = img[start[0]:start[0]+size[0],start[1]:start[1]+size[1]]\n",
    "    mask = np.zeros(img.shape)\n",
    "    mask[start[0]:start[0]+size[0],start[1]:start[1]+size[1]] = 1\n",
    "    return roi, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51daa8a",
   "metadata": {},
   "source": [
    "### Extract Features from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd4402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img, roi_pos):\n",
    "    roi_mask_arr = []\n",
    "    for pos in roi_pos:\n",
    "        roi_mask_arr.append(extract_roi(img, pos))\n",
    "    \n",
    "    # 0 45 90 135 degrees\n",
    "    angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
    "    \n",
    "    da_dict = {\n",
    "        0: \"d1_0\",\n",
    "        1: \"d1_45\",\n",
    "        2: \"d1_90\",\n",
    "        3: \"d1_135\",\n",
    "        \n",
    "        4: \"d2_0\",\n",
    "        5: \"d2_45\",\n",
    "        6: \"d2_90\",\n",
    "        7: \"d2_135\",\n",
    "        \n",
    "        8: \"d3_0\",\n",
    "        9: \"d3_45\",\n",
    "        10: \"d3_90\",\n",
    "        11: \"d3_135\",\n",
    "        \n",
    "    }\n",
    "    \n",
    "    feat_arr = []\n",
    "    for roi, mask in roi_mask_arr:\n",
    "        features = {}\n",
    "        \n",
    "        glcm_mtx = greycomatrix(roi, distances = [1,2,3], angles = angles, levels = 256)\n",
    "        con = greycoprops(glcm_mtx, 'contrast').flatten()\n",
    "        hom = greycoprops(glcm_mtx, 'homogeneity').flatten()\n",
    "        en = greycoprops(glcm_mtx, 'energy').flatten()\n",
    "        corr = greycoprops(glcm_mtx, 'correlation').flatten()\n",
    "        \n",
    "        for j in range(len(da_dict)):\n",
    "            features[f'contrast_{da_dict[j]}'] = con[j]\n",
    "            features[f'homogeneity_{da_dict[j]}'] = hom[j]\n",
    "            features[f'energy_{da_dict[j]}'] = en[j]\n",
    "            features[f'correlation_{da_dict[j]}'] = corr[j]\n",
    "            \n",
    "        features[f'entropy'] = shannon_entropy(roi)\n",
    "        \n",
    "        features[f'mean'] = np.mean(roi)\n",
    "        features[f'variance'] = np.var(roi)\n",
    "        \n",
    "        # pyradiomics\n",
    "        mask = sitk.GetImageFromArray(mask)\n",
    "        # GLCM features\n",
    "        glcmFeatures = glcm.RadiomicsGLCM(img, mask)\n",
    "        glcmFeatures.enableAllFeatures()\n",
    "        results = glcmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        \n",
    "        # GLRLM features\n",
    "        glrlmFeatures = glrlm.RadiomicsGLRLM(img, mask)\n",
    "        glrlmFeatures.enableAllFeatures()\n",
    "        results = glrlmFeatures.execute()\n",
    "        \n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        \n",
    "        feat_arr.append(features)\n",
    "        \n",
    "    return feat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486a2d3",
   "metadata": {},
   "source": [
    "### Construct dataframe from ROI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0f2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(images):\n",
    "    # dataframe consists of features of 1 ROI per image\n",
    "    # column name roiNum_feature\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for img, cls, mask in images:\n",
    "        feat_arr = feature_extraction(img, roi_pos=mask)\n",
    "        for row in feat_arr:\n",
    "            row['target'] = cls\n",
    "            data = data.append(row,ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c31aa7",
   "metadata": {},
   "source": [
    "### Construct dataframe using multiprocessing\n",
    "### Reduced runtime by 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f1592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_with_mlp(images, n=9): \n",
    "    pool = mlp.Pool(n)\n",
    "    results = pool.map(fe.build_dataframe,np.array_split(images,n))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639b10c",
   "metadata": {},
   "source": [
    "## Feature Analysis and Selection\n",
    "\n",
    "### Extract Features and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d7f03422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 167 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1.875000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.607947</td>\n",
       "      <td>78.450133</td>\n",
       "      <td>5.265885</td>\n",
       "      <td>6.796472</td>\n",
       "      <td>0.534181</td>\n",
       "      <td>1.057417</td>\n",
       "      <td>0.273418</td>\n",
       "      <td>0.536117</td>\n",
       "      <td>0.254731</td>\n",
       "      <td>7.737835e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188472</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.169810</td>\n",
       "      <td>0.118795</td>\n",
       "      <td>0.148841</td>\n",
       "      <td>0.117156</td>\n",
       "      <td>0.123361</td>\n",
       "      <td>0.113331</td>\n",
       "      <td>63.740117</td>\n",
       "      <td>159.733414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.157389</td>\n",
       "      <td>27.822747</td>\n",
       "      <td>2.935076</td>\n",
       "      <td>18.132138</td>\n",
       "      <td>1.969909</td>\n",
       "      <td>0.894590</td>\n",
       "      <td>0.149987</td>\n",
       "      <td>0.148141</td>\n",
       "      <td>0.124245</td>\n",
       "      <td>2.413614e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>0.064099</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>0.068449</td>\n",
       "      <td>0.053321</td>\n",
       "      <td>0.055464</td>\n",
       "      <td>0.053904</td>\n",
       "      <td>24.273363</td>\n",
       "      <td>153.209079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.367119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.044883</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.035131</td>\n",
       "      <td>0.036691</td>\n",
       "      <td>0.031642</td>\n",
       "      <td>2.023438</td>\n",
       "      <td>3.118103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>58.700000</td>\n",
       "      <td>3.249825</td>\n",
       "      <td>0.909022</td>\n",
       "      <td>-0.106256</td>\n",
       "      <td>0.569849</td>\n",
       "      <td>0.166310</td>\n",
       "      <td>0.437385</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>6.338971e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>0.100899</td>\n",
       "      <td>0.115812</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>0.093532</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.070858</td>\n",
       "      <td>46.347168</td>\n",
       "      <td>59.755928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>79.700000</td>\n",
       "      <td>4.539973</td>\n",
       "      <td>2.138432</td>\n",
       "      <td>0.153262</td>\n",
       "      <td>0.833975</td>\n",
       "      <td>0.235635</td>\n",
       "      <td>0.525369</td>\n",
       "      <td>0.231164</td>\n",
       "      <td>7.685916e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188360</td>\n",
       "      <td>0.146820</td>\n",
       "      <td>0.161081</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>0.147429</td>\n",
       "      <td>0.111746</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.106542</td>\n",
       "      <td>64.274414</td>\n",
       "      <td>111.377326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>6.776047</td>\n",
       "      <td>5.294571</td>\n",
       "      <td>0.474892</td>\n",
       "      <td>1.276992</td>\n",
       "      <td>0.379435</td>\n",
       "      <td>0.634107</td>\n",
       "      <td>0.352453</td>\n",
       "      <td>9.597778e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233789</td>\n",
       "      <td>0.184354</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.145168</td>\n",
       "      <td>0.183088</td>\n",
       "      <td>0.142910</td>\n",
       "      <td>0.149219</td>\n",
       "      <td>0.139533</td>\n",
       "      <td>80.636719</td>\n",
       "      <td>214.108139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>21.507170</td>\n",
       "      <td>444.720620</td>\n",
       "      <td>34.921036</td>\n",
       "      <td>13.172388</td>\n",
       "      <td>0.877211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596986</td>\n",
       "      <td>1.343032e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741631</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.775769</td>\n",
       "      <td>0.673950</td>\n",
       "      <td>0.697514</td>\n",
       "      <td>0.620327</td>\n",
       "      <td>0.699876</td>\n",
       "      <td>0.623982</td>\n",
       "      <td>149.471680</td>\n",
       "      <td>2049.339576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count   1875.000000   1875.000000      1875.000000        1875.000000   \n",
       "mean      49.607947     78.450133         5.265885           6.796472   \n",
       "std       22.157389     27.822747         2.935076          18.132138   \n",
       "min        0.000000      6.000000         1.000000           0.000000   \n",
       "25%       34.000000     58.700000         3.249825           0.909022   \n",
       "50%       49.000000     79.700000         4.539973           2.138432   \n",
       "75%       64.000000     98.000000         6.776047           5.294571   \n",
       "max      132.000000    170.000000        21.507170         444.720620   \n",
       "\n",
       "       ClusterShade  ClusterTendency     Contrast  Correlation  \\\n",
       "count   1875.000000      1875.000000  1875.000000  1875.000000   \n",
       "mean       0.534181         1.057417     0.273418     0.536117   \n",
       "std        1.969909         0.894590     0.149987     0.148141   \n",
       "min       -8.367119         0.000000     0.000000    -0.002694   \n",
       "25%       -0.106256         0.569849     0.166310     0.437385   \n",
       "50%        0.153262         0.833975     0.235635     0.525369   \n",
       "75%        0.474892         1.276992     0.379435     0.634107   \n",
       "max       34.921036        13.172388     0.877211     1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d2_0  \\\n",
       "count        1875.000000       1.875000e+03  ...       1875.000000   \n",
       "mean            0.254731       7.737835e-01  ...          0.188472   \n",
       "std             0.124245       2.413614e-01  ...          0.084368   \n",
       "min             0.000000      -3.203427e-16  ...          0.049637   \n",
       "25%             0.164957       6.338971e-01  ...          0.121571   \n",
       "50%             0.231164       7.685916e-01  ...          0.188360   \n",
       "75%             0.352453       9.597778e-01  ...          0.233789   \n",
       "max             0.596986       1.343032e+00  ...          0.741631   \n",
       "\n",
       "       homogeneity_d2_135  homogeneity_d2_45  homogeneity_d2_90  \\\n",
       "count         1875.000000        1875.000000        1875.000000   \n",
       "mean             0.151202           0.169810           0.118795   \n",
       "std              0.064099           0.074271           0.053416   \n",
       "min              0.048944           0.044883           0.030550   \n",
       "25%              0.100899           0.115812           0.075160   \n",
       "50%              0.146820           0.161081           0.113689   \n",
       "75%              0.184354           0.205439           0.145168   \n",
       "max              0.701923           0.775769           0.673950   \n",
       "\n",
       "       homogeneity_d3_0  homogeneity_d3_135  homogeneity_d3_45  \\\n",
       "count       1875.000000         1875.000000        1875.000000   \n",
       "mean           0.148841            0.117156           0.123361   \n",
       "std            0.068449            0.053321           0.055464   \n",
       "min            0.041362            0.035131           0.036691   \n",
       "25%            0.093532            0.075949           0.081603   \n",
       "50%            0.147429            0.111746           0.117534   \n",
       "75%            0.183088            0.142910           0.149219   \n",
       "max            0.697514            0.620327           0.699876   \n",
       "\n",
       "       homogeneity_d3_90         mean     variance  \n",
       "count        1875.000000  1875.000000  1875.000000  \n",
       "mean            0.113331    63.740117   159.733414  \n",
       "std             0.053904    24.273363   153.209079  \n",
       "min             0.031642     2.023438     3.118103  \n",
       "25%             0.070858    46.347168    59.755928  \n",
       "50%             0.106542    64.274414   111.377326  \n",
       "75%             0.139533    80.636719   214.108139  \n",
       "max             0.623982   149.471680  2049.339576  \n",
       "\n",
       "[8 rows x 109 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# images = read_images('dataset/train')\n",
    "# mlp_data = build_with_mlp(images)\n",
    "# data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     data = data.append(frame)\n",
    "\n",
    "# data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# data.to_csv(\"dataset/train.csv\")\n",
    "\n",
    "data = pd.read_csv('dataset/train.csv', index_col='name')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cba1dff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 128 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.00000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>3.820000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.217277</td>\n",
       "      <td>79.27644</td>\n",
       "      <td>5.295707</td>\n",
       "      <td>7.244694</td>\n",
       "      <td>0.579809</td>\n",
       "      <td>1.082905</td>\n",
       "      <td>0.261253</td>\n",
       "      <td>0.554878</td>\n",
       "      <td>0.244751</td>\n",
       "      <td>7.640925e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185952</td>\n",
       "      <td>0.147653</td>\n",
       "      <td>0.176052</td>\n",
       "      <td>0.120195</td>\n",
       "      <td>0.146332</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.125761</td>\n",
       "      <td>0.115112</td>\n",
       "      <td>64.354444</td>\n",
       "      <td>162.414246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.434761</td>\n",
       "      <td>27.34130</td>\n",
       "      <td>2.853370</td>\n",
       "      <td>17.294010</td>\n",
       "      <td>2.246493</td>\n",
       "      <td>0.853788</td>\n",
       "      <td>0.137671</td>\n",
       "      <td>0.145262</td>\n",
       "      <td>0.113077</td>\n",
       "      <td>2.203017e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.056312</td>\n",
       "      <td>0.073037</td>\n",
       "      <td>0.051804</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.054049</td>\n",
       "      <td>0.051733</td>\n",
       "      <td>24.211294</td>\n",
       "      <td>143.825166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.508871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063136</td>\n",
       "      <td>0.057985</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.046913</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.039154</td>\n",
       "      <td>0.034577</td>\n",
       "      <td>3.886719</td>\n",
       "      <td>5.821152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>60.25000</td>\n",
       "      <td>3.509715</td>\n",
       "      <td>0.894214</td>\n",
       "      <td>-0.104566</td>\n",
       "      <td>0.552214</td>\n",
       "      <td>0.167227</td>\n",
       "      <td>0.451109</td>\n",
       "      <td>0.164111</td>\n",
       "      <td>6.380821e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124603</td>\n",
       "      <td>0.108026</td>\n",
       "      <td>0.124869</td>\n",
       "      <td>0.082521</td>\n",
       "      <td>0.099154</td>\n",
       "      <td>0.079586</td>\n",
       "      <td>0.089632</td>\n",
       "      <td>0.077233</td>\n",
       "      <td>47.729248</td>\n",
       "      <td>62.612046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>4.721010</td>\n",
       "      <td>2.237011</td>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.825854</td>\n",
       "      <td>0.227071</td>\n",
       "      <td>0.552495</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>7.549453e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183858</td>\n",
       "      <td>0.147430</td>\n",
       "      <td>0.165739</td>\n",
       "      <td>0.115742</td>\n",
       "      <td>0.140288</td>\n",
       "      <td>0.111879</td>\n",
       "      <td>0.118271</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>65.222656</td>\n",
       "      <td>112.277640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>97.00000</td>\n",
       "      <td>6.858440</td>\n",
       "      <td>6.281702</td>\n",
       "      <td>0.529058</td>\n",
       "      <td>1.381738</td>\n",
       "      <td>0.343392</td>\n",
       "      <td>0.654871</td>\n",
       "      <td>0.322666</td>\n",
       "      <td>9.290920e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232590</td>\n",
       "      <td>0.176334</td>\n",
       "      <td>0.213714</td>\n",
       "      <td>0.144507</td>\n",
       "      <td>0.179333</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>0.148503</td>\n",
       "      <td>0.135590</td>\n",
       "      <td>80.237061</td>\n",
       "      <td>220.327254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>16.215100</td>\n",
       "      <td>218.165215</td>\n",
       "      <td>27.204337</td>\n",
       "      <td>6.577641</td>\n",
       "      <td>0.748138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577532</td>\n",
       "      <td>1.288810e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567898</td>\n",
       "      <td>0.533208</td>\n",
       "      <td>0.601422</td>\n",
       "      <td>0.451463</td>\n",
       "      <td>0.487847</td>\n",
       "      <td>0.414726</td>\n",
       "      <td>0.481178</td>\n",
       "      <td>0.408715</td>\n",
       "      <td>138.832031</td>\n",
       "      <td>974.315304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count    382.000000     382.00000       382.000000         382.000000   \n",
       "mean      50.217277      79.27644         5.295707           7.244694   \n",
       "std       22.434761      27.34130         2.853370          17.294010   \n",
       "min        1.000000       7.00000         1.000000           0.000000   \n",
       "25%       35.000000      60.25000         3.509715           0.894214   \n",
       "50%       50.000000      80.00000         4.721010           2.237011   \n",
       "75%       62.000000      97.00000         6.858440           6.281702   \n",
       "max      128.000000     150.00000        16.215100         218.165215   \n",
       "\n",
       "       ClusterShade  ClusterTendency    Contrast  Correlation  \\\n",
       "count    382.000000       382.000000  382.000000   382.000000   \n",
       "mean       0.579809         1.082905    0.261253     0.554878   \n",
       "std        2.246493         0.853788    0.137671     0.145262   \n",
       "min       -3.508871         0.000000    0.000000    -0.000639   \n",
       "25%       -0.104566         0.552214    0.167227     0.451109   \n",
       "50%        0.208912         0.825854    0.227071     0.552495   \n",
       "75%        0.529058         1.381738    0.343392     0.654871   \n",
       "max       27.204337         6.577641    0.748138     1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d2_0  \\\n",
       "count         382.000000       3.820000e+02  ...        382.000000   \n",
       "mean            0.244751       7.640925e-01  ...          0.185952   \n",
       "std             0.113077       2.203017e-01  ...          0.073204   \n",
       "min             0.000000      -3.203427e-16  ...          0.063136   \n",
       "25%             0.164111       6.380821e-01  ...          0.124603   \n",
       "50%             0.223359       7.549453e-01  ...          0.183858   \n",
       "75%             0.322666       9.290920e-01  ...          0.232590   \n",
       "max             0.577532       1.288810e+00  ...          0.567898   \n",
       "\n",
       "       homogeneity_d2_135  homogeneity_d2_45  homogeneity_d2_90  \\\n",
       "count          382.000000         382.000000         382.000000   \n",
       "mean             0.147653           0.176052           0.120195   \n",
       "std              0.056312           0.073037           0.051804   \n",
       "min              0.057985           0.055655           0.031740   \n",
       "25%              0.108026           0.124869           0.082521   \n",
       "50%              0.147430           0.165739           0.115742   \n",
       "75%              0.176334           0.213714           0.144507   \n",
       "max              0.533208           0.601422           0.451463   \n",
       "\n",
       "       homogeneity_d3_0  homogeneity_d3_135  homogeneity_d3_45  \\\n",
       "count        382.000000          382.000000         382.000000   \n",
       "mean           0.146332            0.117783           0.125761   \n",
       "std            0.059865            0.051189           0.054049   \n",
       "min            0.046913            0.037576           0.039154   \n",
       "25%            0.099154            0.079586           0.089632   \n",
       "50%            0.140288            0.111879           0.118271   \n",
       "75%            0.179333            0.136750           0.148503   \n",
       "max            0.487847            0.414726           0.481178   \n",
       "\n",
       "       homogeneity_d3_90        mean    variance  \n",
       "count         382.000000  382.000000  382.000000  \n",
       "mean            0.115112   64.354444  162.414246  \n",
       "std             0.051733   24.211294  143.825166  \n",
       "min             0.034577    3.886719    5.821152  \n",
       "25%             0.077233   47.729248   62.612046  \n",
       "50%             0.107708   65.222656  112.277640  \n",
       "75%             0.135590   80.237061  220.327254  \n",
       "max             0.408715  138.832031  974.315304  \n",
       "\n",
       "[8 rows x 109 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# test_images = read_images(\"dataset/test\")\n",
    "# mlp_data = build_with_mlp(test_images)\n",
    "# test_data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     test_data = test_data.append(frame)\n",
    "    \n",
    "# test_data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# test_data.to_csv(\"dataset/test.csv\")\n",
    "\n",
    "test_data = pd.read_csv('dataset/test.csv', index_col='name')\n",
    "\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d096d2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)+len(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fab083",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "af4b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_data, drop):\n",
    "    X_train = data.copy()#.drop(['name'], axis=1)\n",
    "    y_train = X_train.pop('target')\n",
    "    X_test = test_data.copy()#.drop(['name'], axis=1)\n",
    "    y_test = X_test.pop('target')\n",
    "\n",
    "    X_train = X_train[y_train != drop]\n",
    "    X_test = X_test[y_test != drop]\n",
    "\n",
    "    y_train = y_train[y_train != drop]\n",
    "    y_test = y_test[y_test != drop]\n",
    "\n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train)\n",
    "    X_train = pd.DataFrame(std.transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "    X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    return X_train, y_train, X_test, y_test, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "de6d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(model.predict(X_test),index=y_test.index)\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "261fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_pred(y_pred):\n",
    "    count = 0\n",
    "    prediction = {}\n",
    "    for name in np.unique(y_pred.index):\n",
    "        pred_cls = {}\n",
    "        for i in y_pred[name]:\n",
    "            if i not in pred_cls.keys():\n",
    "                pred_cls[i]=1\n",
    "            else: pred_cls[i]+=1\n",
    "        \n",
    "        prediction[name] = max(pred_cls, key=pred_cls.get)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "93aedb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_acc(y_test, y_pred):\n",
    "    pred_count = 0\n",
    "    for key in y_pred.keys():\n",
    "        if y_test[key][0] == y_pred[key]:\n",
    "            pred_count += 1\n",
    "    return pred_count/len(y_pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0889f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatty cirrhosis\n",
      "RFC  Image Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.860465  0.474359  0.611570   78.000000\n",
      "fatty          0.784211  0.961290  0.863768  155.000000\n",
      "accuracy       0.798283  0.798283  0.798283    0.798283\n",
      "macro avg      0.822338  0.717825  0.737669  233.000000\n",
      "weighted avg   0.809738  0.798283  0.779341  233.000000\n",
      "MLP  Image Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.724138  0.538462  0.617647   78.000000\n",
      "fatty          0.794286  0.896774  0.842424  155.000000\n",
      "accuracy       0.776824  0.776824  0.776824    0.776824\n",
      "macro avg      0.759212  0.717618  0.730036  233.000000\n",
      "weighted avg   0.770803  0.776824  0.767177  233.000000\n",
      "SVC  Image Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score   support\n",
      "cirrhosis      0.795918  0.500000  0.614173   78.0000\n",
      "fatty          0.788043  0.935484  0.855457  155.0000\n",
      "accuracy       0.789700  0.789700  0.789700    0.7897\n",
      "macro avg      0.791981  0.717742  0.734815  233.0000\n",
      "weighted avg   0.790680  0.789700  0.774684  233.0000\n",
      "\n",
      "\n",
      "\n",
      "normal cirrhosis\n",
      "RFC  Image Accuracy:  0.6842105263157895\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.461538  0.076923  0.131868   78.000000\n",
      "normal         0.663551  0.953020  0.782369  149.000000\n",
      "accuracy       0.651982  0.651982  0.651982    0.651982\n",
      "macro avg      0.562545  0.514972  0.457119  227.000000\n",
      "weighted avg   0.594137  0.651982  0.558849  227.000000\n",
      "MLP  Image Accuracy:  0.7368421052631579\n",
      "              precision    recall  f1-score    support\n",
      "cirrhosis      0.571429  0.410256  0.477612   78.00000\n",
      "normal         0.730994  0.838926  0.781250  149.00000\n",
      "accuracy       0.691630  0.691630  0.691630    0.69163\n",
      "macro avg      0.651211  0.624591  0.629431  227.00000\n",
      "weighted avg   0.676165  0.691630  0.676916  227.00000\n",
      "SVC  Image Accuracy:  0.6842105263157895\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.555556  0.192308  0.285714   78.000000\n",
      "normal         0.685000  0.919463  0.785100  149.000000\n",
      "accuracy       0.669604  0.669604  0.669604    0.669604\n",
      "macro avg      0.620278  0.555885  0.535407  227.000000\n",
      "weighted avg   0.640521  0.669604  0.613505  227.000000\n",
      "\n",
      "\n",
      "\n",
      "normal fatty\n",
      "RFC  Image Accuracy:  0.7586206896551724\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.710983  0.793548  0.750000  155.000000\n",
      "normal         0.755725  0.664430  0.707143  149.000000\n",
      "accuracy       0.730263  0.730263  0.730263    0.730263\n",
      "macro avg      0.733354  0.728989  0.728571  304.000000\n",
      "weighted avg   0.732912  0.730263  0.728994  304.000000\n",
      "MLP  Image Accuracy:  0.6896551724137931\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.677019  0.703226  0.689873  155.000000\n",
      "normal         0.678322  0.651007  0.664384  149.000000\n",
      "accuracy       0.677632  0.677632  0.677632    0.677632\n",
      "macro avg      0.677670  0.677116  0.677128  304.000000\n",
      "weighted avg   0.677657  0.677632  0.677380  304.000000\n",
      "SVC  Image Accuracy:  0.6551724137931034\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.637306  0.793548  0.706897  155.000000\n",
      "normal         0.711712  0.530201  0.607692  149.000000\n",
      "accuracy       0.664474  0.664474  0.664474    0.664474\n",
      "macro avg      0.674509  0.661875  0.657294  304.000000\n",
      "weighted avg   0.673774  0.664474  0.658273  304.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RFC\": RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    max_features='auto',\n",
    "                    n_estimators= 500,\n",
    "                    max_depth=6,\n",
    "                    criterion='entropy'),\n",
    "    \"MLP\": MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001),\n",
    "    \"SVC\": svm.SVC()\n",
    "}\n",
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "\n",
    "for drop in classes:\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop)\n",
    "    print(*[cls for cls in classes if cls != drop])\n",
    "    for name in models.keys():\n",
    "        model, y_pred = train_test(models[name], X_train, y_train, X_test, y_test)\n",
    "        prediction = images_pred(y_pred)\n",
    "        print(name,\" Image Accuracy: \", images_acc(y_test, prediction))\n",
    "        report = classification_report(y_test, y_pred, output_dict = True)\n",
    "        cr = pd.DataFrame(report).transpose()\n",
    "        print(cr)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "96b60ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Fatty MLP Image Accuracy:  0.8275862068965517\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.697531  0.729032  0.712934  155.000000\n",
      "normal         0.704225  0.671141  0.687285  149.000000\n",
      "accuracy       0.700658  0.700658  0.700658    0.700658\n",
      "macro avg      0.700878  0.700087  0.700109  304.000000\n",
      "weighted avg   0.700812  0.700658  0.700363  304.000000\n"
     ]
    }
   ],
   "source": [
    "normal_fatty_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "X_train, y_train, X_test, y_test, normal_fatty_std = split(data, test_data, 'cirrhosis')\n",
    "model, y_pred = train_test(normal_fatty_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_fatty_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "30cbeaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal/cirrhosis MLP Image Accuracy:  0.7894736842105263\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.619048  0.500000  0.553191   78.000000\n",
      "normal         0.762195  0.838926  0.798722  149.000000\n",
      "accuracy       0.722467  0.722467  0.722467    0.722467\n",
      "macro avg      0.690621  0.669463  0.675957  227.000000\n",
      "weighted avg   0.713008  0.722467  0.714355  227.000000\n"
     ]
    }
   ],
   "source": [
    "normal_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "X_train, y_train, X_test, y_test, normal_cirrhosis_std = split(data, test_data, 'fatty')\n",
    "model, y_pred = train_test(normal_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"normal/cirrhosis MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b67e2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cirrhosis/Fatty MLP Image Accuracy:  0.9090909090909091\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.765625  0.628205  0.690141   78.000000\n",
      "fatty          0.828402  0.903226  0.864198  155.000000\n",
      "accuracy       0.811159  0.811159  0.811159    0.811159\n",
      "macro avg      0.797014  0.765715  0.777169  233.000000\n",
      "weighted avg   0.807387  0.811159  0.805930  233.000000\n"
     ]
    }
   ],
   "source": [
    "fatty_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "X_train, y_train, X_test, y_test, fatty_cirrhosis_std = split(data, test_data, 'normal')\n",
    "model, y_pred = train_test(fatty_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "fatty_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "341e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"normal_fatty\": (normal_fatty_mlp, normal_fatty_std),\n",
    "    \"normal_cirrhosis\": (normal_cirrhosis_mlp, normal_cirrhosis_std),\n",
    "    \"fatty_cirrhosis\": (fatty_cirrhosis_mlp, fatty_cirrhosis_std)\n",
    "}\n",
    "\n",
    "X_test = test_data.copy()\n",
    "y_test = X_test.pop('target')\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "52782718",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "predictions = {}\n",
    "for name in models.keys():\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "    X_test = pd.DataFrame(models[name][1].transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    y_pred = pd.Series(models[name][0].predict(X_test),index=y_test.index)\n",
    "    predictions[name] = images_pred(y_pred)\n",
    "    \n",
    "image_names = np.unique(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ebd475fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = np.unique(y_test.index)\n",
    "final_pred = {}\n",
    "for image in image_name:\n",
    "    pred = {\n",
    "        'normal': 0,\n",
    "        'fatty': 0,\n",
    "        'cirrhosis': 0\n",
    "    }\n",
    "    for model in predictions.keys():\n",
    "        pred[predictions[model][image]] += 1\n",
    "    cls = max(pred, key=pred.get)\n",
    "    if pred[cls] == 1:\n",
    "        final_pred[image] = 'abstain'\n",
    "    else: final_pred[image] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2387b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_acc(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "424c72bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "cirrhosis      0.666667  0.400000  0.500000   5.000000\n",
      "fatty          0.789474  0.937500  0.857143  16.000000\n",
      "normal         0.666667  0.615385  0.640000  13.000000\n",
      "accuracy       0.735294  0.735294  0.735294   0.735294\n",
      "macro avg      0.707602  0.650962  0.665714  34.000000\n",
      "weighted avg   0.724458  0.735294  0.721597  34.000000\n",
      "Abstention Rate:  0.02857142857142857\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test[~y_test.index.duplicated(keep='first')].sort_index()\n",
    "y_pred = pd.Series(final_pred).sort_index()\n",
    "abstain = y_pred[y_pred=='abstain'].index\n",
    "\n",
    "y_test = y_test.drop(abstain)\n",
    "y_pred = y_pred.drop(abstain)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)\n",
    "print(\"Abstention Rate: \", len(abstain)/(len(y_pred)+len(abstain)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9bfa024",
   "metadata": {},
   "source": [
    "from joblib import dump\n",
    "\n",
    "for name in models.keys():\n",
    "    dump(models[name][0], f'dataset/models/{name}_mlp.joblib') \n",
    "    dump(models[name][1], f'dataset/models/{name}_std.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d32a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
