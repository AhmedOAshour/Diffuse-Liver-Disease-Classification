{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5bb83d",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de7e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import greycomatrix\n",
    "from skimage.feature.texture import greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from radiomics import glrlm, glcm\n",
    "# import pyfeats\\\\\n",
    "import pandas as pd\n",
    "import multiprocessing as mlp\n",
    "import math\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcb13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe50bfe",
   "metadata": {},
   "source": [
    "## Define Feature Extraction functions\n",
    "\n",
    "### Read dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder = \"dataset/train\",\n",
    "                classes = [\n",
    "                            \"normal\",\n",
    "                            \"fatty\",\n",
    "                            \"cirrhosis\"\n",
    "                        ]):\n",
    "    image_names = {}\n",
    "    images = []\n",
    "    # Get all image names in folders\n",
    "    for cls in classes:\n",
    "        image_names[cls] = os.listdir(f'{folder}/{cls}')\n",
    "\n",
    "    # read all images to list\n",
    "    for cls in classes:\n",
    "        for name in image_names[cls]:\n",
    "            mask = []\n",
    "            with open(f'dataset/masks/{name[0:-4]}.txt', 'r') as file:\n",
    "                data = file.read()\n",
    "                data = data.strip().split('\\n')\n",
    "                for line in data:\n",
    "                    x, y = line.split(',')\n",
    "                    mask.append((int(y),int(x)))\n",
    "            img = sitk.ReadImage(f'{folder}/{cls}/{name}', sitk.sitkUInt8)\n",
    "            images.append((name, img,cls,mask))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0a6a1",
   "metadata": {},
   "source": [
    "### Extract ROIs from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4160da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(img, start , size = (32,32)):\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    roi = img[start[0]:start[0]+size[0],start[1]:start[1]+size[1]]\n",
    "    mask = np.zeros(img.shape)\n",
    "    mask[start[0]:start[0]+size[0],start[1]:start[1]+size[1]] = 1\n",
    "    return roi, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73316262",
   "metadata": {},
   "source": [
    "# Calculate Liver Diagonal Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7cf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(img, mask):\n",
    "    # top right, bottom left\n",
    "    tr_distance = []\n",
    "    bl_distance = []\n",
    "\n",
    "    # top left, bottom right\n",
    "    tl_distance = []\n",
    "    br_distance = []\n",
    "\n",
    "\n",
    "    for x,y in mask:\n",
    "        tr_distance.append(math.dist([0,img.shape[1]],[x+32,y]))\n",
    "        bl_distance.append(math.dist([img.shape[0],0],[x,y+32]))\n",
    "\n",
    "        tl_distance.append(math.dist([0,0],[x,y]))\n",
    "        br_distance.append(math.dist(img.shape,[x+32,y+32]))\n",
    "\n",
    "\n",
    "    top_right = mask[tr_distance.index(min(tr_distance))]\n",
    "    bottom_left = mask[bl_distance.index(min(bl_distance))]\n",
    "\n",
    "    top_left = mask[tl_distance.index(min(tl_distance))]\n",
    "    bottom_right = mask[br_distance.index(min(br_distance))]\n",
    "    \n",
    "    return max(math.dist(top_right,bottom_left),math.dist(top_left,bottom_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51daa8a",
   "metadata": {},
   "source": [
    "### Extract Features from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd4402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img, roi_pos):\n",
    "    roi_mask_arr = []\n",
    "    for pos in roi_pos:\n",
    "        roi_mask_arr.append(extract_roi(img, pos))\n",
    "\n",
    "    # 0 45 90 135 degrees\n",
    "    angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
    "\n",
    "    da_dict = {\n",
    "        0: \"d1_0\",1: \"d1_45\",2: \"d1_90\",3: \"d1_135\",\n",
    "        4: \"d2_0\",5: \"d2_45\",6: \"d2_90\",7: \"d2_135\",\n",
    "        8: \"d3_0\",9: \"d3_45\",10: \"d3_90\",11: \"d3_135\"\n",
    "    }\n",
    "\n",
    "    length = get_length(sitk.GetArrayFromImage(img), roi_pos)\n",
    "\n",
    "    feat_arr = []\n",
    "    for roi, mask in roi_mask_arr:\n",
    "        features = {}\n",
    "\n",
    "        glcm_mtx = greycomatrix(roi, distances = [1,2,3], angles = angles, levels = 256)\n",
    "        con = greycoprops(glcm_mtx, 'contrast').flatten()\n",
    "        hom = greycoprops(glcm_mtx, 'homogeneity').flatten()\n",
    "        en = greycoprops(glcm_mtx, 'energy').flatten()\n",
    "        corr = greycoprops(glcm_mtx, 'correlation').flatten()\n",
    "\n",
    "        for j in range(len(da_dict)):\n",
    "            features[f'contrast_{da_dict[j]}'] = con[j]\n",
    "            features[f'homogeneity_{da_dict[j]}'] = hom[j]\n",
    "            features[f'energy_{da_dict[j]}'] = en[j]\n",
    "            features[f'correlation_{da_dict[j]}'] = corr[j]\n",
    "\n",
    "        features[f'entropy'] = shannon_entropy(roi)\n",
    "\n",
    "        features['length'] = length\n",
    "\n",
    "        # pyradiomics\n",
    "        mask = sitk.GetImageFromArray(mask)\n",
    "        # First Order features\n",
    "        firstOrderFeatures = firstorder.RadiomicsFirstOrder(img, mask)\n",
    "        # firstOrderFeatures.enableFeatureByName('Mean', True)\n",
    "        firstOrderFeatures.enableAllFeatures()\n",
    "        results = firstOrderFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "\n",
    "        # GLCM features\n",
    "        glcmFeatures = glcm.RadiomicsGLCM(img, mask)\n",
    "        glcmFeatures.enableAllFeatures()\n",
    "        results = glcmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        #\n",
    "        # GLRLM features\n",
    "        glrlmFeatures = glrlm.RadiomicsGLRLM(img, mask)\n",
    "        glrlmFeatures.enableAllFeatures()\n",
    "        results = glrlmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "\n",
    "        feat_arr.append(features)\n",
    "\n",
    "    return feat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486a2d3",
   "metadata": {},
   "source": [
    "### Construct dataframe from ROI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0f2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(images):\n",
    "    # dataframe consists of features of 1 ROI per image\n",
    "    # column name roiNum_feature\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for img, cls, mask in images:\n",
    "        feat_arr = feature_extraction(img, roi_pos=mask)\n",
    "        for row in feat_arr:\n",
    "            row['target'] = cls\n",
    "            data = data.append(row,ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c31aa7",
   "metadata": {},
   "source": [
    "### Construct dataframe using multiprocessing\n",
    "### Reduced runtime by 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f1592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_with_mlp(images, n=9): \n",
    "    pool = mlp.Pool(n)\n",
    "    results = pool.map(fe.build_dataframe,np.array_split(images,n))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639b10c",
   "metadata": {},
   "source": [
    "## Feature Analysis and Selection\n",
    "\n",
    "### Extract Features and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7f03422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d1_90</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>1.023900e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "      <td>10239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.214386</td>\n",
       "      <td>70.884881</td>\n",
       "      <td>5.190461</td>\n",
       "      <td>27.420777</td>\n",
       "      <td>2.159861</td>\n",
       "      <td>1.169789</td>\n",
       "      <td>0.316116</td>\n",
       "      <td>0.520472</td>\n",
       "      <td>0.246282</td>\n",
       "      <td>7.505986e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177287</td>\n",
       "      <td>0.197639</td>\n",
       "      <td>0.162198</td>\n",
       "      <td>0.192916</td>\n",
       "      <td>0.140118</td>\n",
       "      <td>0.162515</td>\n",
       "      <td>0.137177</td>\n",
       "      <td>0.146077</td>\n",
       "      <td>0.135427</td>\n",
       "      <td>294.342970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.953822</td>\n",
       "      <td>33.997997</td>\n",
       "      <td>4.488373</td>\n",
       "      <td>176.498185</td>\n",
       "      <td>12.593087</td>\n",
       "      <td>1.654653</td>\n",
       "      <td>0.331033</td>\n",
       "      <td>0.171877</td>\n",
       "      <td>0.128860</td>\n",
       "      <td>2.695262e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109722</td>\n",
       "      <td>0.113970</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.118423</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.106142</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>0.104579</td>\n",
       "      <td>0.101120</td>\n",
       "      <td>72.108890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.744314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>0.050039</td>\n",
       "      <td>0.042185</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.034135</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>0.035083</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>135.764502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.729294</td>\n",
       "      <td>0.870617</td>\n",
       "      <td>-0.024615</td>\n",
       "      <td>0.534995</td>\n",
       "      <td>0.170213</td>\n",
       "      <td>0.407430</td>\n",
       "      <td>0.163213</td>\n",
       "      <td>6.255283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117785</td>\n",
       "      <td>0.130055</td>\n",
       "      <td>0.109110</td>\n",
       "      <td>0.122657</td>\n",
       "      <td>0.093496</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>0.090946</td>\n",
       "      <td>0.094952</td>\n",
       "      <td>0.089072</td>\n",
       "      <td>243.704739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>4.182663</td>\n",
       "      <td>2.084719</td>\n",
       "      <td>0.282485</td>\n",
       "      <td>0.807595</td>\n",
       "      <td>0.254504</td>\n",
       "      <td>0.513868</td>\n",
       "      <td>0.238976</td>\n",
       "      <td>7.787500e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154595</td>\n",
       "      <td>0.173784</td>\n",
       "      <td>0.141294</td>\n",
       "      <td>0.165697</td>\n",
       "      <td>0.117997</td>\n",
       "      <td>0.140509</td>\n",
       "      <td>0.115081</td>\n",
       "      <td>0.122553</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>286.216701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>6.122207</td>\n",
       "      <td>9.357921</td>\n",
       "      <td>0.876473</td>\n",
       "      <td>1.345874</td>\n",
       "      <td>0.373407</td>\n",
       "      <td>0.625236</td>\n",
       "      <td>0.323690</td>\n",
       "      <td>9.169306e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197679</td>\n",
       "      <td>0.226263</td>\n",
       "      <td>0.178031</td>\n",
       "      <td>0.223166</td>\n",
       "      <td>0.151147</td>\n",
       "      <td>0.180674</td>\n",
       "      <td>0.147460</td>\n",
       "      <td>0.161069</td>\n",
       "      <td>0.146184</td>\n",
       "      <td>340.164666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>66.896373</td>\n",
       "      <td>5954.836767</td>\n",
       "      <td>390.534435</td>\n",
       "      <td>39.317592</td>\n",
       "      <td>10.517470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.587563</td>\n",
       "      <td>1.962372e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>480.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count  10239.000000  10239.000000     10239.000000       10239.000000   \n",
       "mean      43.214386     70.884881         5.190461          27.420777   \n",
       "std       25.953822     33.997997         4.488373         176.498185   \n",
       "min        0.000000      0.000000         1.000000           0.000000   \n",
       "25%       24.000000     46.000000         2.729294           0.870617   \n",
       "50%       41.000000     69.000000         4.182663           2.084719   \n",
       "75%       60.000000     91.000000         6.122207           9.357921   \n",
       "max      174.000000    253.000000        66.896373        5954.836767   \n",
       "\n",
       "       ClusterShade  ClusterTendency      Contrast   Correlation  \\\n",
       "count  10239.000000     10239.000000  10239.000000  10239.000000   \n",
       "mean       2.159861         1.169789      0.316116      0.520472   \n",
       "std       12.593087         1.654653      0.331033      0.171877   \n",
       "min      -20.744314         0.000000      0.000000     -0.003308   \n",
       "25%       -0.024615         0.534995      0.170213      0.407430   \n",
       "50%        0.282485         0.807595      0.254504      0.513868   \n",
       "75%        0.876473         1.345874      0.373407      0.625236   \n",
       "max      390.534435        39.317592     10.517470      1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d1_90  \\\n",
       "count       10239.000000       1.023900e+04  ...       10239.000000   \n",
       "mean            0.246282       7.505986e-01  ...           0.177287   \n",
       "std             0.128860       2.695262e-01  ...           0.109722   \n",
       "min             0.000000      -3.203427e-16  ...           0.041775   \n",
       "25%             0.163213       6.255283e-01  ...           0.117785   \n",
       "50%             0.238976       7.787500e-01  ...           0.154595   \n",
       "75%             0.323690       9.169306e-01  ...           0.197679   \n",
       "max             1.587563       1.962372e+00  ...           1.000000   \n",
       "\n",
       "       homogeneity_d2_0  homogeneity_d2_135  homogeneity_d2_45  \\\n",
       "count      10239.000000        10239.000000       10239.000000   \n",
       "mean           0.197639            0.162198           0.192916   \n",
       "std            0.113970            0.104919           0.118423   \n",
       "min            0.050039            0.042185           0.043133   \n",
       "25%            0.130055            0.109110           0.122657   \n",
       "50%            0.173784            0.141294           0.165697   \n",
       "75%            0.226263            0.178031           0.223166   \n",
       "max            1.000000            1.000000           1.000000   \n",
       "\n",
       "       homogeneity_d2_90  homogeneity_d3_0  homogeneity_d3_135  \\\n",
       "count       10239.000000      10239.000000        10239.000000   \n",
       "mean            0.140118          0.162515            0.137177   \n",
       "std             0.101432          0.106142            0.100996   \n",
       "min             0.034135          0.039906            0.035083   \n",
       "25%             0.093496          0.106743            0.090946   \n",
       "50%             0.117997          0.140509            0.115081   \n",
       "75%             0.151147          0.180674            0.147460   \n",
       "max             1.000000          1.000000            1.000000   \n",
       "\n",
       "       homogeneity_d3_45  homogeneity_d3_90        length  \n",
       "count       10239.000000       10239.000000  10239.000000  \n",
       "mean            0.146077           0.135427    294.342970  \n",
       "std             0.104579           0.101120     72.108890  \n",
       "min             0.034000           0.027464    135.764502  \n",
       "25%             0.094952           0.089072    243.704739  \n",
       "50%             0.122553           0.112606    286.216701  \n",
       "75%             0.161069           0.146184    340.164666  \n",
       "max             1.000000           1.000000    480.000000  \n",
       "\n",
       "[8 rows x 108 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# images = read_images('dataset/train')\n",
    "# mlp_data = build_with_mlp(images)\n",
    "# data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     data = data.append(frame)\n",
    "\n",
    "# data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# data.to_csv(\"dataset/train.csv\")\n",
    "\n",
    "data = pd.read_excel('dataset/segment/train.xlsx', index_col='name')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba1dff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.35 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d1_90</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2.543000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "      <td>2543.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42.901219</td>\n",
       "      <td>71.010814</td>\n",
       "      <td>5.015083</td>\n",
       "      <td>26.339400</td>\n",
       "      <td>2.002938</td>\n",
       "      <td>1.167737</td>\n",
       "      <td>0.314198</td>\n",
       "      <td>0.516472</td>\n",
       "      <td>0.250870</td>\n",
       "      <td>7.536736e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176278</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.161127</td>\n",
       "      <td>0.192916</td>\n",
       "      <td>0.140383</td>\n",
       "      <td>0.162683</td>\n",
       "      <td>0.138232</td>\n",
       "      <td>0.146238</td>\n",
       "      <td>0.136276</td>\n",
       "      <td>293.332709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.602086</td>\n",
       "      <td>35.537199</td>\n",
       "      <td>4.006853</td>\n",
       "      <td>201.157591</td>\n",
       "      <td>13.729393</td>\n",
       "      <td>1.703052</td>\n",
       "      <td>0.340934</td>\n",
       "      <td>0.170138</td>\n",
       "      <td>0.138701</td>\n",
       "      <td>2.863724e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114381</td>\n",
       "      <td>0.116635</td>\n",
       "      <td>0.109106</td>\n",
       "      <td>0.123798</td>\n",
       "      <td>0.106084</td>\n",
       "      <td>0.108893</td>\n",
       "      <td>0.105759</td>\n",
       "      <td>0.109164</td>\n",
       "      <td>0.105858</td>\n",
       "      <td>66.869642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.731914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>0.038131</td>\n",
       "      <td>0.047311</td>\n",
       "      <td>0.034038</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.032659</td>\n",
       "      <td>135.764502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.542497</td>\n",
       "      <td>0.861262</td>\n",
       "      <td>-0.008815</td>\n",
       "      <td>0.524250</td>\n",
       "      <td>0.168639</td>\n",
       "      <td>0.408831</td>\n",
       "      <td>0.161579</td>\n",
       "      <td>6.248237e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116269</td>\n",
       "      <td>0.130361</td>\n",
       "      <td>0.108888</td>\n",
       "      <td>0.121239</td>\n",
       "      <td>0.091311</td>\n",
       "      <td>0.107111</td>\n",
       "      <td>0.090186</td>\n",
       "      <td>0.093158</td>\n",
       "      <td>0.087530</td>\n",
       "      <td>243.704739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.091035</td>\n",
       "      <td>1.934584</td>\n",
       "      <td>0.275089</td>\n",
       "      <td>0.815074</td>\n",
       "      <td>0.251024</td>\n",
       "      <td>0.504155</td>\n",
       "      <td>0.241261</td>\n",
       "      <td>7.808226e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151490</td>\n",
       "      <td>0.172473</td>\n",
       "      <td>0.137961</td>\n",
       "      <td>0.161490</td>\n",
       "      <td>0.116903</td>\n",
       "      <td>0.139648</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.121216</td>\n",
       "      <td>0.113159</td>\n",
       "      <td>295.025423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>6.060370</td>\n",
       "      <td>8.418262</td>\n",
       "      <td>0.766716</td>\n",
       "      <td>1.332241</td>\n",
       "      <td>0.380118</td>\n",
       "      <td>0.618500</td>\n",
       "      <td>0.331848</td>\n",
       "      <td>9.225272e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193826</td>\n",
       "      <td>0.228049</td>\n",
       "      <td>0.175607</td>\n",
       "      <td>0.219497</td>\n",
       "      <td>0.150460</td>\n",
       "      <td>0.182794</td>\n",
       "      <td>0.149007</td>\n",
       "      <td>0.159531</td>\n",
       "      <td>0.147083</td>\n",
       "      <td>329.460165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>40.840677</td>\n",
       "      <td>5220.689962</td>\n",
       "      <td>333.676485</td>\n",
       "      <td>31.207490</td>\n",
       "      <td>9.178053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.135032</td>\n",
       "      <td>1.526040e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>435.247056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count   2543.000000   2543.000000      2543.000000        2543.000000   \n",
       "mean      42.901219     71.010814         5.015083          26.339400   \n",
       "std       26.602086     35.537199         4.006853         201.157591   \n",
       "min        0.000000      0.000000         1.000000           0.000000   \n",
       "25%       24.000000     45.000000         2.542497           0.861262   \n",
       "50%       41.000000     68.000000         4.091035           1.934584   \n",
       "75%       62.000000     93.000000         6.060370           8.418262   \n",
       "max      135.000000    253.000000        40.840677        5220.689962   \n",
       "\n",
       "       ClusterShade  ClusterTendency     Contrast  Correlation  \\\n",
       "count   2543.000000      2543.000000  2543.000000  2543.000000   \n",
       "mean       2.002938         1.167737     0.314198     0.516472   \n",
       "std       13.729393         1.703052     0.340934     0.170138   \n",
       "min      -13.731914         0.000000     0.000000    -0.003336   \n",
       "25%       -0.008815         0.524250     0.168639     0.408831   \n",
       "50%        0.275089         0.815074     0.251024     0.504155   \n",
       "75%        0.766716         1.332241     0.380118     0.618500   \n",
       "max      333.676485        31.207490     9.178053     1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d1_90  \\\n",
       "count        2543.000000       2.543000e+03  ...        2543.000000   \n",
       "mean            0.250870       7.536736e-01  ...           0.176278   \n",
       "std             0.138701       2.863724e-01  ...           0.114381   \n",
       "min             0.000000      -3.203427e-16  ...           0.046256   \n",
       "25%             0.161579       6.248237e-01  ...           0.116269   \n",
       "50%             0.241261       7.808226e-01  ...           0.151490   \n",
       "75%             0.331848       9.225272e-01  ...           0.193826   \n",
       "max             1.135032       1.526040e+00  ...           1.000000   \n",
       "\n",
       "       homogeneity_d2_0  homogeneity_d2_135  homogeneity_d2_45  \\\n",
       "count       2543.000000         2543.000000        2543.000000   \n",
       "mean           0.197346            0.161127           0.192916   \n",
       "std            0.116635            0.109106           0.123798   \n",
       "min            0.049470            0.038131           0.047311   \n",
       "25%            0.130361            0.108888           0.121239   \n",
       "50%            0.172473            0.137961           0.161490   \n",
       "75%            0.228049            0.175607           0.219497   \n",
       "max            1.000000            1.000000           1.000000   \n",
       "\n",
       "       homogeneity_d2_90  homogeneity_d3_0  homogeneity_d3_135  \\\n",
       "count        2543.000000       2543.000000         2543.000000   \n",
       "mean            0.140383          0.162683            0.138232   \n",
       "std             0.106084          0.108893            0.105759   \n",
       "min             0.034038          0.039583            0.034590   \n",
       "25%             0.091311          0.107111            0.090186   \n",
       "50%             0.116903          0.139648            0.114804   \n",
       "75%             0.150460          0.182794            0.149007   \n",
       "max             1.000000          1.000000            1.000000   \n",
       "\n",
       "       homogeneity_d3_45  homogeneity_d3_90       length  \n",
       "count        2543.000000        2543.000000  2543.000000  \n",
       "mean            0.146238           0.136276   293.332709  \n",
       "std             0.109164           0.105858    66.869642  \n",
       "min             0.035135           0.032659   135.764502  \n",
       "25%             0.093158           0.087530   243.704739  \n",
       "50%             0.121216           0.113159   295.025423  \n",
       "75%             0.159531           0.147083   329.460165  \n",
       "max             1.000000           1.000000   435.247056  \n",
       "\n",
       "[8 rows x 108 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# test_images = read_images(\"dataset/test\")\n",
    "# mlp_data = build_with_mlp(test_images)\n",
    "# test_data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     test_data = test_data.append(frame)\n",
    "    \n",
    "# test_data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# test_data.to_csv(\"dataset/test.csv\")\n",
    "\n",
    "test_data = pd.read_excel('dataset/segment/test.xlsx', index_col='name')\n",
    "\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fab083",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_data, drop=None, cols = None):\n",
    "    X_train = data.copy()\n",
    "    y_train = X_train.pop('target')\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "\n",
    "    if drop != None:\n",
    "        X_train = X_train[y_train != drop]\n",
    "        X_test = X_test[y_test != drop]\n",
    "\n",
    "        y_train = y_train[y_train != drop]\n",
    "        y_test = y_test[y_test != drop]\n",
    "    \n",
    "    if cols is None: cols = X_train.columns\n",
    "    \n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train[cols])\n",
    "    X_train = pd.DataFrame(std.transform(X_train[cols]), columns = cols, index = X_train.index)\n",
    "    X_test = pd.DataFrame(std.transform(X_test[cols]), columns = cols, index = X_test.index)\n",
    "    return X_train, y_train, X_test, y_test, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(model.predict(X_test),index=y_test.index)\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "261fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_pred(y_pred):\n",
    "    count = 0\n",
    "    prediction = {}\n",
    "    for name in np.unique(y_pred.index):\n",
    "        pred_cls = {}\n",
    "        for i in y_pred[name]:\n",
    "            if i not in pred_cls.keys():\n",
    "                pred_cls[i]=1\n",
    "            else: pred_cls[i]+=1\n",
    "        \n",
    "        prediction[name] = max(pred_cls, key=pred_cls.get)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93aedb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_acc(y_test, y_pred):\n",
    "    pred_count = 0\n",
    "    for key in y_pred.keys():\n",
    "        if y_test[key][0] == y_pred[key]:\n",
    "            pred_count += 1\n",
    "    return pred_count/len(y_pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653fa695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatty cirrhosis\n",
      "RFC  Image Accuracy:  0.8\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.731707  0.066667  0.122200   450.00000\n",
      "fatty          0.788520  0.993025  0.879035  1577.00000\n",
      "accuracy       0.787370  0.787370  0.787370     0.78737\n",
      "macro avg      0.760113  0.529846  0.500617  2027.00000\n",
      "weighted avg   0.775907  0.787370  0.711015  2027.00000\n",
      "MLP  Image Accuracy:  0.8461538461538461\n",
      "              precision    recall  f1-score      support\n",
      "cirrhosis      0.550595  0.411111  0.470738   450.000000\n",
      "fatty          0.843288  0.904249  0.872705  1577.000000\n",
      "accuracy       0.794771  0.794771  0.794771     0.794771\n",
      "macro avg      0.696942  0.657680  0.671721  2027.000000\n",
      "weighted avg   0.778309  0.794771  0.783467  2027.000000\n",
      "SVC  Image Accuracy:  0.8\n",
      "              precision    recall  f1-score      support\n",
      "cirrhosis      0.714286  0.066667  0.121951   450.000000\n",
      "fatty          0.788413  0.992391  0.878720  1577.000000\n",
      "accuracy       0.786877  0.786877  0.786877     0.786877\n",
      "macro avg      0.751349  0.529529  0.500336  2027.000000\n",
      "weighted avg   0.771957  0.786877  0.710715  2027.000000\n",
      "\n",
      "\n",
      "\n",
      "normal cirrhosis\n",
      "RFC  Image Accuracy:  0.6428571428571429\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.773504  0.402222  0.529240  450.000000\n",
      "normal         0.632514  0.897287  0.741987  516.000000\n",
      "accuracy       0.666667  0.666667  0.666667    0.666667\n",
      "macro avg      0.703009  0.649755  0.635613  966.000000\n",
      "weighted avg   0.698193  0.666667  0.642881  966.000000\n",
      "MLP  Image Accuracy:  0.6071428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.580977  0.502222  0.538737  450.000000\n",
      "normal         0.611785  0.684109  0.645929  516.000000\n",
      "accuracy       0.599379  0.599379  0.599379    0.599379\n",
      "macro avg      0.596381  0.593165  0.592333  966.000000\n",
      "weighted avg   0.597433  0.599379  0.595994  966.000000\n",
      "SVC  Image Accuracy:  0.6071428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.637883  0.508889  0.566131  450.000000\n",
      "normal         0.635914  0.748062  0.687444  516.000000\n",
      "accuracy       0.636646  0.636646  0.636646    0.636646\n",
      "macro avg      0.636899  0.628475  0.626788  966.000000\n",
      "weighted avg   0.636831  0.636646  0.630932  966.000000\n",
      "\n",
      "\n",
      "\n",
      "normal fatty\n",
      "RFC  Image Accuracy:  0.8208955223880597\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.774690  0.989854  0.869154  1577.000000\n",
      "normal         0.794872  0.120155  0.208754   516.000000\n",
      "accuracy       0.775442  0.775442  0.775442     0.775442\n",
      "macro avg      0.784781  0.555005  0.538954  2093.000000\n",
      "weighted avg   0.779665  0.775442  0.706341  2093.000000\n",
      "MLP  Image Accuracy:  0.8208955223880597\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.849237  0.846544  0.847888  1577.000000\n",
      "normal         0.535509  0.540698  0.538091   516.000000\n",
      "accuracy       0.771142  0.771142  0.771142     0.771142\n",
      "macro avg      0.692373  0.693621  0.692989  2093.000000\n",
      "weighted avg   0.771891  0.771142  0.771512  2093.000000\n",
      "SVC  Image Accuracy:  0.8208955223880597\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.784513  0.976538  0.870056  1577.00000\n",
      "normal         0.715385  0.180233  0.287926   516.00000\n",
      "accuracy       0.780220  0.780220  0.780220     0.78022\n",
      "macro avg      0.749949  0.578385  0.578991  2093.00000\n",
      "weighted avg   0.767471  0.780220  0.726540  2093.00000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RFC\": RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    max_features='auto',\n",
    "                    n_estimators= 500,\n",
    "                    max_depth=6,\n",
    "                    criterion='entropy'),\n",
    "    \"MLP\": MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=42),\n",
    "    \"SVC\": svm.SVC(random_state=42)\n",
    "}\n",
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "\n",
    "for drop in classes:\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop)\n",
    "    print(*[cls for cls in classes if cls != drop])\n",
    "    for name in models.keys():\n",
    "        model, y_pred = train_test(models[name], X_train, y_train, X_test, y_test)\n",
    "        prediction = images_pred(y_pred)\n",
    "        print(name,\" Image Accuracy: \", images_acc(y_test, prediction))\n",
    "        report = classification_report(y_test, y_pred, output_dict = True)\n",
    "        cr = pd.DataFrame(report).transpose()\n",
    "        print(cr)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38fb4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat importance\n",
    "files = ['fatty_normal', 'cirrhosis_fatty', 'cirrhosis_normal']\n",
    "features_acc={}\n",
    "for name in files:\n",
    "    features_acc[name] = pd.read_csv(f'dataset/segment/manual selection/{name}.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96b60ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Fatty MLP Image Accuracy:  0.8059701492537313\n",
      "              precision    recall  f1-score      support\n",
      "fatty          0.800961  0.951807  0.869893  1577.000000\n",
      "normal         0.652968  0.277132  0.389116   516.000000\n",
      "accuracy       0.785475  0.785475  0.785475     0.785475\n",
      "macro avg      0.726964  0.614470  0.629504  2093.000000\n",
      "weighted avg   0.764475  0.785475  0.751364  2093.000000\n"
     ]
    }
   ],
   "source": [
    "normal_fatty_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=31\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['fatty_normal']['ANN Accuracy'].sort_values(ascending=False)\n",
    "normal_fatty_cols = feat_imp.index[0:19]\n",
    "\n",
    "X_train, y_train, X_test, y_test, normal_fatty_std = split(data, test_data, 'cirrhosis', cols = normal_fatty_cols)\n",
    "model, y_pred = train_test(normal_fatty_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_fatty_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30cbeaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal/cirrhosis MLP Image Accuracy:  0.6071428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.604423  0.546667  0.574096  450.000000\n",
      "normal         0.635063  0.687984  0.660465  516.000000\n",
      "accuracy       0.622153  0.622153  0.622153    0.622153\n",
      "macro avg      0.619743  0.617326  0.617280  966.000000\n",
      "weighted avg   0.620789  0.622153  0.620231  966.000000\n"
     ]
    }
   ],
   "source": [
    "normal_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=81\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['cirrhosis_normal']['ANN Accuracy'].sort_values(ascending=False)\n",
    "normal_cirrhosis_cols = feat_imp.index[0:21].insert(0,'length')\n",
    "X_train, y_train, X_test, y_test, normal_cirrhosis_std = split(data, test_data, 'fatty', cols = normal_cirrhosis_cols)\n",
    "model, y_pred = train_test(normal_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"normal/cirrhosis MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b67e2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cirrhosis/Fatty MLP Image Accuracy:  0.8153846153846154\n",
      "              precision    recall  f1-score      support\n",
      "cirrhosis      0.535065  0.457778  0.493413   450.000000\n",
      "fatty          0.851401  0.886493  0.868593  1577.000000\n",
      "accuracy       0.791317  0.791317  0.791317     0.791317\n",
      "macro avg      0.693233  0.672136  0.681003  2027.000000\n",
      "weighted avg   0.781173  0.791317  0.785302  2027.000000\n"
     ]
    }
   ],
   "source": [
    "fatty_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=53\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['cirrhosis_fatty']['ANN Accuracy'].sort_values(ascending=False)\n",
    "fatty_cirrhosis_cols = feat_imp.index[0:63].insert(0,'length')\n",
    "\n",
    "X_train, y_train, X_test, y_test, fatty_cirrhosis_std = split(data, test_data, 'normal', cols = fatty_cirrhosis_cols)\n",
    "model, y_pred = train_test(fatty_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "fatty_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "341e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"normal_fatty\": (normal_fatty_mlp, normal_fatty_std, normal_fatty_cols),\n",
    "    \"normal_cirrhosis\": (normal_cirrhosis_mlp, normal_cirrhosis_std, normal_cirrhosis_cols),\n",
    "    \"fatty_cirrhosis\": (fatty_cirrhosis_mlp, fatty_cirrhosis_std, fatty_cirrhosis_cols)\n",
    "}\n",
    "\n",
    "X_test = test_data.copy()\n",
    "y_test = X_test.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52782718",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "for name in models.keys():\n",
    "    cols = models[name][2]\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "    X_test = pd.DataFrame(models[name][1].transform(X_test[cols]), columns = cols, index = X_test.index)\n",
    "    X_test =  X_test[cols]\n",
    "    y_pred = pd.Series(models[name][0].predict(X_test),index=y_test.index)\n",
    "    predictions[name] = images_pred(y_pred)\n",
    "    \n",
    "image_names = np.unique(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebd475fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = np.unique(y_test.index)\n",
    "final_pred = {}\n",
    "for image in image_name:\n",
    "    pred = {\n",
    "        'normal': 0,\n",
    "        'fatty': 0,\n",
    "        'cirrhosis': 0\n",
    "    }\n",
    "    for model in predictions.keys():\n",
    "        pred[predictions[model][image]] += 1\n",
    "    cls = max(pred, key=pred.get)\n",
    "    if pred[cls] == 1:\n",
    "        final_pred[image] = 'abstain'\n",
    "    else: final_pred[image] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2387b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_acc(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "424c72bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "cirrhosis      0.142857  0.125000  0.133333   8.000000\n",
      "fatty          0.734375  0.921569  0.817391  51.000000\n",
      "normal         1.000000  0.142857  0.250000  14.000000\n",
      "accuracy       0.684932  0.684932  0.684932   0.684932\n",
      "macro avg      0.625744  0.396475  0.400242  73.000000\n",
      "weighted avg   0.720493  0.684932  0.633611  73.000000\n",
      "Abstention Rate:  0.0875\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test[~y_test.index.duplicated(keep='first')].sort_index()\n",
    "y_pred = pd.Series(final_pred).sort_index()\n",
    "abstain = y_pred[y_pred=='abstain'].index\n",
    "\n",
    "y_test = y_test.drop(abstain)\n",
    "y_pred = y_pred.drop(abstain)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)\n",
    "print(\"Abstention Rate: \", len(abstain)/(len(y_pred)+len(abstain)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2e47e3d",
   "metadata": {},
   "source": [
    "features_acc = pd.read_excel('dataset/manual selection/multiclass/multiclass.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c15c7f6",
   "metadata": {},
   "source": [
    "features_acc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be7e5226",
   "metadata": {},
   "source": [
    "multiclass_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001,\n",
    "                    random_state=42\n",
    "                    )\n",
    "\n",
    "feat_imp = features_acc['ANN Accuracy'].sort_values(ascending=False)\n",
    "multiclass_cols = feat_imp.index[0:97].insert(0,'length')\n",
    "\n",
    "X_train, y_train, X_test, y_test, multiclass_std = split(data, test_data, cols = multiclass_cols)\n",
    "model, y_pred = train_test(multiclass_mlp, X_train, y_train, X_test, y_test)\n",
    "multiclass_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c178100e",
   "metadata": {},
   "source": [
    "from joblib import dump\n",
    "\n",
    "for name in models.keys():\n",
    "    dump(models[name][0], f'dataset/models/{name}_mlp.joblib') \n",
    "    dump(models[name][1], f'dataset/models/{name}_std.joblib') \n",
    "    dump(models[name][2], f'dataset/models/{name}_cols.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
