{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5bb83d",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de7e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import greycomatrix\n",
    "from skimage.feature.texture import greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from radiomics import glrlm, glcm\n",
    "# import pyfeats\n",
    "import pandas as pd\n",
    "import multiprocessing as mlp\n",
    "import math\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcb13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe50bfe",
   "metadata": {},
   "source": [
    "## Define Feature Extraction functions\n",
    "\n",
    "### Read dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder = \"dataset/train\",\n",
    "                classes = [\n",
    "                            \"normal\",\n",
    "                            \"fatty\",\n",
    "                            \"cirrhosis\"\n",
    "                        ]):\n",
    "    image_names = {}\n",
    "    images = []\n",
    "    # Get all image names in folders\n",
    "    for cls in classes:\n",
    "        image_names[cls] = os.listdir(f'{folder}/{cls}')\n",
    "\n",
    "    # read all images to list\n",
    "    for cls in classes:\n",
    "        for name in image_names[cls]:\n",
    "            mask = []\n",
    "            with open(f'dataset/masks/{name[0:-4]}.txt', 'r') as file:\n",
    "                data = file.read()\n",
    "                data = data.strip().split('\\n')\n",
    "                for line in data:\n",
    "                    x, y = line.split(',')\n",
    "                    mask.append((int(y),int(x)))\n",
    "            img = sitk.ReadImage(f'{folder}/{cls}/{name}', sitk.sitkUInt8)\n",
    "            images.append((name, img,cls,mask))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0a6a1",
   "metadata": {},
   "source": [
    "### Extract ROIs from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4160da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(img, start , size = (32,32)):\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    roi = img[start[0]:start[0]+size[0],start[1]:start[1]+size[1]]\n",
    "    mask = np.zeros(img.shape)\n",
    "    mask[start[0]:start[0]+size[0],start[1]:start[1]+size[1]] = 1\n",
    "    return roi, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51daa8a",
   "metadata": {},
   "source": [
    "### Extract Features from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd4402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img, roi_pos):\n",
    "    roi_mask_arr = []\n",
    "    for pos in roi_pos:\n",
    "        roi_mask_arr.append(extract_roi(img, pos))\n",
    "    \n",
    "    # 0 45 90 135 degrees\n",
    "    angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
    "    \n",
    "    da_dict = {\n",
    "        0: \"d1_0\",\n",
    "        1: \"d1_45\",\n",
    "        2: \"d1_90\",\n",
    "        3: \"d1_135\",\n",
    "        \n",
    "        4: \"d2_0\",\n",
    "        5: \"d2_45\",\n",
    "        6: \"d2_90\",\n",
    "        7: \"d2_135\",\n",
    "        \n",
    "        8: \"d3_0\",\n",
    "        9: \"d3_45\",\n",
    "        10: \"d3_90\",\n",
    "        11: \"d3_135\",\n",
    "        \n",
    "    }\n",
    "    \n",
    "    feat_arr = []\n",
    "    for roi, mask in roi_mask_arr:\n",
    "        features = {}\n",
    "        \n",
    "        glcm_mtx = greycomatrix(roi, distances = [1,2,3], angles = angles, levels = 256)\n",
    "        con = greycoprops(glcm_mtx, 'contrast').flatten()\n",
    "        hom = greycoprops(glcm_mtx, 'homogeneity').flatten()\n",
    "        en = greycoprops(glcm_mtx, 'energy').flatten()\n",
    "        corr = greycoprops(glcm_mtx, 'correlation').flatten()\n",
    "        \n",
    "        for j in range(len(da_dict)):\n",
    "            features[f'contrast_{da_dict[j]}'] = con[j]\n",
    "            features[f'homogeneity_{da_dict[j]}'] = hom[j]\n",
    "            features[f'energy_{da_dict[j]}'] = en[j]\n",
    "            features[f'correlation_{da_dict[j]}'] = corr[j]\n",
    "            \n",
    "        features[f'entropy'] = shannon_entropy(roi)\n",
    "        \n",
    "        features[f'mean'] = np.mean(roi)\n",
    "        features[f'variance'] = np.var(roi)\n",
    "        \n",
    "        # pyradiomics\n",
    "        mask = sitk.GetImageFromArray(mask)\n",
    "        # GLCM features\n",
    "        glcmFeatures = glcm.RadiomicsGLCM(img, mask)\n",
    "        glcmFeatures.enableAllFeatures()\n",
    "        results = glcmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        \n",
    "        # GLRLM features\n",
    "        glrlmFeatures = glrlm.RadiomicsGLRLM(img, mask)\n",
    "        glrlmFeatures.enableAllFeatures()\n",
    "        results = glrlmFeatures.execute()\n",
    "        \n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        \n",
    "        feat_arr.append(features)\n",
    "        \n",
    "    return feat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486a2d3",
   "metadata": {},
   "source": [
    "### Construct dataframe from ROI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0f2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(images):\n",
    "    # dataframe consists of features of 1 ROI per image\n",
    "    # column name roiNum_feature\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for img, cls, mask in images:\n",
    "        feat_arr = feature_extraction(img, roi_pos=mask)\n",
    "        for row in feat_arr:\n",
    "            row['target'] = cls\n",
    "            data = data.append(row,ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c31aa7",
   "metadata": {},
   "source": [
    "### Construct dataframe using multiprocessing\n",
    "### Reduced runtime by 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f1592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_with_mlp(images, n=9): \n",
    "    pool = mlp.Pool(n)\n",
    "    results = pool.map(fe.build_dataframe,np.array_split(images,n))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639b10c",
   "metadata": {},
   "source": [
    "## Feature Analysis and Selection\n",
    "\n",
    "### Extract Features and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f03422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 78 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrast_d1_0</th>\n",
       "      <th>contrast_d1_135</th>\n",
       "      <th>contrast_d1_45</th>\n",
       "      <th>contrast_d1_90</th>\n",
       "      <th>contrast_d2_0</th>\n",
       "      <th>contrast_d2_135</th>\n",
       "      <th>contrast_d2_45</th>\n",
       "      <th>contrast_d2_90</th>\n",
       "      <th>contrast_d3_0</th>\n",
       "      <th>contrast_d3_135</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "      <td>1267.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139.519073</td>\n",
       "      <td>557.327588</td>\n",
       "      <td>463.135449</td>\n",
       "      <td>467.277785</td>\n",
       "      <td>391.737471</td>\n",
       "      <td>557.327588</td>\n",
       "      <td>463.135449</td>\n",
       "      <td>917.244892</td>\n",
       "      <td>604.282498</td>\n",
       "      <td>934.884076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101468</td>\n",
       "      <td>0.079234</td>\n",
       "      <td>0.088752</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>0.079006</td>\n",
       "      <td>0.060838</td>\n",
       "      <td>0.064240</td>\n",
       "      <td>0.058601</td>\n",
       "      <td>127.256808</td>\n",
       "      <td>644.009706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>147.724657</td>\n",
       "      <td>443.369671</td>\n",
       "      <td>361.772842</td>\n",
       "      <td>324.136137</td>\n",
       "      <td>375.169488</td>\n",
       "      <td>443.369671</td>\n",
       "      <td>361.772842</td>\n",
       "      <td>663.401978</td>\n",
       "      <td>523.149730</td>\n",
       "      <td>720.873546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.036489</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>0.039828</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>0.032205</td>\n",
       "      <td>0.030541</td>\n",
       "      <td>43.200174</td>\n",
       "      <td>518.192499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.794355</td>\n",
       "      <td>18.226847</td>\n",
       "      <td>11.097815</td>\n",
       "      <td>14.074597</td>\n",
       "      <td>8.593750</td>\n",
       "      <td>18.226847</td>\n",
       "      <td>11.097815</td>\n",
       "      <td>22.135417</td>\n",
       "      <td>14.056034</td>\n",
       "      <td>21.187778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027087</td>\n",
       "      <td>0.028164</td>\n",
       "      <td>0.022842</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>5.323242</td>\n",
       "      <td>16.139197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.826613</td>\n",
       "      <td>210.973985</td>\n",
       "      <td>174.550989</td>\n",
       "      <td>193.190020</td>\n",
       "      <td>107.746875</td>\n",
       "      <td>210.973985</td>\n",
       "      <td>174.550989</td>\n",
       "      <td>365.588542</td>\n",
       "      <td>190.837823</td>\n",
       "      <td>366.636111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065678</td>\n",
       "      <td>0.055286</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.051134</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.044599</td>\n",
       "      <td>0.039480</td>\n",
       "      <td>99.199219</td>\n",
       "      <td>275.739315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66.564516</td>\n",
       "      <td>378.600416</td>\n",
       "      <td>345.700312</td>\n",
       "      <td>385.714718</td>\n",
       "      <td>211.425000</td>\n",
       "      <td>378.600416</td>\n",
       "      <td>345.700312</td>\n",
       "      <td>713.570833</td>\n",
       "      <td>366.661638</td>\n",
       "      <td>692.543333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093708</td>\n",
       "      <td>0.072779</td>\n",
       "      <td>0.078808</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.071948</td>\n",
       "      <td>0.055350</td>\n",
       "      <td>0.056327</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>128.371094</td>\n",
       "      <td>530.385830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.776210</td>\n",
       "      <td>851.488554</td>\n",
       "      <td>710.325702</td>\n",
       "      <td>711.252520</td>\n",
       "      <td>634.913021</td>\n",
       "      <td>851.488554</td>\n",
       "      <td>710.325702</td>\n",
       "      <td>1362.885417</td>\n",
       "      <td>986.370690</td>\n",
       "      <td>1388.037778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123839</td>\n",
       "      <td>0.092408</td>\n",
       "      <td>0.105918</td>\n",
       "      <td>0.071139</td>\n",
       "      <td>0.095446</td>\n",
       "      <td>0.070792</td>\n",
       "      <td>0.075588</td>\n",
       "      <td>0.069197</td>\n",
       "      <td>159.161133</td>\n",
       "      <td>843.983488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>796.198589</td>\n",
       "      <td>2356.312175</td>\n",
       "      <td>2041.617066</td>\n",
       "      <td>1757.277218</td>\n",
       "      <td>1811.351042</td>\n",
       "      <td>2356.312175</td>\n",
       "      <td>2041.617066</td>\n",
       "      <td>3990.372917</td>\n",
       "      <td>2863.830819</td>\n",
       "      <td>4558.567778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571401</td>\n",
       "      <td>0.557161</td>\n",
       "      <td>0.601520</td>\n",
       "      <td>0.539195</td>\n",
       "      <td>0.556561</td>\n",
       "      <td>0.490969</td>\n",
       "      <td>0.553843</td>\n",
       "      <td>0.494561</td>\n",
       "      <td>242.736328</td>\n",
       "      <td>4191.302077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       contrast_d1_0  contrast_d1_135  contrast_d1_45  contrast_d1_90  \\\n",
       "count    1267.000000      1267.000000     1267.000000     1267.000000   \n",
       "mean      139.519073       557.327588      463.135449      467.277785   \n",
       "std       147.724657       443.369671      361.772842      324.136137   \n",
       "min         2.794355        18.226847       11.097815       14.074597   \n",
       "25%        33.826613       210.973985      174.550989      193.190020   \n",
       "50%        66.564516       378.600416      345.700312      385.714718   \n",
       "75%       218.776210       851.488554      710.325702      711.252520   \n",
       "max       796.198589      2356.312175     2041.617066     1757.277218   \n",
       "\n",
       "       contrast_d2_0  contrast_d2_135  contrast_d2_45  contrast_d2_90  \\\n",
       "count    1267.000000      1267.000000     1267.000000     1267.000000   \n",
       "mean      391.737471       557.327588      463.135449      917.244892   \n",
       "std       375.169488       443.369671      361.772842      663.401978   \n",
       "min         8.593750        18.226847       11.097815       22.135417   \n",
       "25%       107.746875       210.973985      174.550989      365.588542   \n",
       "50%       211.425000       378.600416      345.700312      713.570833   \n",
       "75%       634.913021       851.488554      710.325702     1362.885417   \n",
       "max      1811.351042      2356.312175     2041.617066     3990.372917   \n",
       "\n",
       "       contrast_d3_0  contrast_d3_135  ...  homogeneity_d2_0  \\\n",
       "count    1267.000000      1267.000000  ...       1267.000000   \n",
       "mean      604.282498       934.884076  ...          0.101468   \n",
       "std       523.149730       720.873546  ...          0.049200   \n",
       "min        14.056034        21.187778  ...          0.027087   \n",
       "25%       190.837823       366.636111  ...          0.065678   \n",
       "50%       366.661638       692.543333  ...          0.093708   \n",
       "75%       986.370690      1388.037778  ...          0.123839   \n",
       "max      2863.830819      4558.567778  ...          0.571401   \n",
       "\n",
       "       homogeneity_d2_135  homogeneity_d2_45  homogeneity_d2_90  \\\n",
       "count         1267.000000        1267.000000        1267.000000   \n",
       "mean             0.079234           0.088752           0.061216   \n",
       "std              0.036489           0.043281           0.030509   \n",
       "min              0.028164           0.022842           0.018037   \n",
       "25%              0.055286           0.058626           0.042100   \n",
       "50%              0.072779           0.078808           0.055367   \n",
       "75%              0.092408           0.105918           0.071139   \n",
       "max              0.557161           0.601520           0.539195   \n",
       "\n",
       "       homogeneity_d3_0  homogeneity_d3_135  homogeneity_d3_45  \\\n",
       "count       1267.000000         1267.000000        1267.000000   \n",
       "mean           0.079006            0.060838           0.064240   \n",
       "std            0.039828            0.030627           0.032205   \n",
       "min            0.026600            0.020656           0.021953   \n",
       "25%            0.051134            0.041772           0.044599   \n",
       "50%            0.071948            0.055350           0.056327   \n",
       "75%            0.095446            0.070792           0.075588   \n",
       "max            0.556561            0.490969           0.553843   \n",
       "\n",
       "       homogeneity_d3_90         mean     variance  \n",
       "count        1267.000000  1267.000000  1267.000000  \n",
       "mean            0.058601   127.256808   644.009706  \n",
       "std             0.030541    43.200174   518.192499  \n",
       "min             0.018234     5.323242    16.139197  \n",
       "25%             0.039480    99.199219   275.739315  \n",
       "50%             0.051946   128.371094   530.385830  \n",
       "75%             0.069197   159.161133   843.983488  \n",
       "max             0.494561   242.736328  4191.302077  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# images = read_images('dataset/stretched/train')\n",
    "# mlp_data = build_with_mlp(images)\n",
    "# data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     data = data.append(frame)\n",
    "\n",
    "# data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# data.to_csv(\"dataset/train.csv\")\n",
    "\n",
    "data = pd.read_csv('dataset/train.csv', index_col='name')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba1dff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 73 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrast_d1_0</th>\n",
       "      <th>contrast_d1_135</th>\n",
       "      <th>contrast_d1_45</th>\n",
       "      <th>contrast_d1_90</th>\n",
       "      <th>contrast_d2_0</th>\n",
       "      <th>contrast_d2_135</th>\n",
       "      <th>contrast_d2_45</th>\n",
       "      <th>contrast_d2_90</th>\n",
       "      <th>contrast_d3_0</th>\n",
       "      <th>contrast_d3_135</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.693760</td>\n",
       "      <td>481.666424</td>\n",
       "      <td>391.710732</td>\n",
       "      <td>405.448278</td>\n",
       "      <td>291.567108</td>\n",
       "      <td>481.666424</td>\n",
       "      <td>391.710732</td>\n",
       "      <td>812.619982</td>\n",
       "      <td>475.429606</td>\n",
       "      <td>828.227639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107538</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.094749</td>\n",
       "      <td>0.064927</td>\n",
       "      <td>0.083671</td>\n",
       "      <td>0.065257</td>\n",
       "      <td>0.066878</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>118.604558</td>\n",
       "      <td>612.059621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>111.941397</td>\n",
       "      <td>409.512881</td>\n",
       "      <td>367.517034</td>\n",
       "      <td>334.222091</td>\n",
       "      <td>301.621589</td>\n",
       "      <td>409.512881</td>\n",
       "      <td>367.517034</td>\n",
       "      <td>711.742505</td>\n",
       "      <td>444.706417</td>\n",
       "      <td>735.899216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038212</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>0.037523</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>43.781055</td>\n",
       "      <td>519.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.564516</td>\n",
       "      <td>25.159209</td>\n",
       "      <td>21.857440</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>16.289583</td>\n",
       "      <td>25.159209</td>\n",
       "      <td>21.857440</td>\n",
       "      <td>35.629167</td>\n",
       "      <td>25.405172</td>\n",
       "      <td>34.073333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039628</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.026174</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.024179</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.022595</td>\n",
       "      <td>30.594727</td>\n",
       "      <td>22.063354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.148185</td>\n",
       "      <td>189.221904</td>\n",
       "      <td>134.213059</td>\n",
       "      <td>152.076109</td>\n",
       "      <td>90.478125</td>\n",
       "      <td>189.221904</td>\n",
       "      <td>134.213059</td>\n",
       "      <td>287.708854</td>\n",
       "      <td>160.724138</td>\n",
       "      <td>281.397222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077724</td>\n",
       "      <td>0.062667</td>\n",
       "      <td>0.066959</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>0.060323</td>\n",
       "      <td>0.045083</td>\n",
       "      <td>0.048439</td>\n",
       "      <td>0.042672</td>\n",
       "      <td>86.614502</td>\n",
       "      <td>221.020653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.623992</td>\n",
       "      <td>306.805411</td>\n",
       "      <td>250.070760</td>\n",
       "      <td>286.308972</td>\n",
       "      <td>144.367708</td>\n",
       "      <td>306.805411</td>\n",
       "      <td>250.070760</td>\n",
       "      <td>511.067187</td>\n",
       "      <td>253.303341</td>\n",
       "      <td>518.418333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106529</td>\n",
       "      <td>0.079249</td>\n",
       "      <td>0.089093</td>\n",
       "      <td>0.061241</td>\n",
       "      <td>0.081235</td>\n",
       "      <td>0.061081</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>0.059077</td>\n",
       "      <td>120.194824</td>\n",
       "      <td>425.679302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>148.455645</td>\n",
       "      <td>754.572841</td>\n",
       "      <td>544.886576</td>\n",
       "      <td>608.550907</td>\n",
       "      <td>472.954427</td>\n",
       "      <td>754.572841</td>\n",
       "      <td>544.886576</td>\n",
       "      <td>1233.457812</td>\n",
       "      <td>803.068696</td>\n",
       "      <td>1244.031667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130661</td>\n",
       "      <td>0.095316</td>\n",
       "      <td>0.114242</td>\n",
       "      <td>0.080179</td>\n",
       "      <td>0.103041</td>\n",
       "      <td>0.078092</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.079175</td>\n",
       "      <td>147.738525</td>\n",
       "      <td>810.817033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>533.570565</td>\n",
       "      <td>1741.885536</td>\n",
       "      <td>2010.729448</td>\n",
       "      <td>1515.122984</td>\n",
       "      <td>1349.643750</td>\n",
       "      <td>1741.885536</td>\n",
       "      <td>2010.729448</td>\n",
       "      <td>3065.783333</td>\n",
       "      <td>1961.033405</td>\n",
       "      <td>3096.735556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263151</td>\n",
       "      <td>0.222067</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.188469</td>\n",
       "      <td>0.223884</td>\n",
       "      <td>0.193968</td>\n",
       "      <td>0.196544</td>\n",
       "      <td>0.174825</td>\n",
       "      <td>235.129883</td>\n",
       "      <td>2777.443015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       contrast_d1_0  contrast_d1_135  contrast_d1_45  contrast_d1_90  \\\n",
       "count     224.000000       224.000000      224.000000      224.000000   \n",
       "mean       98.693760       481.666424      391.710732      405.448278   \n",
       "std       111.941397       409.512881      367.517034      334.222091   \n",
       "min         5.564516        25.159209       21.857440       22.250000   \n",
       "25%        28.148185       189.221904      134.213059      152.076109   \n",
       "50%        46.623992       306.805411      250.070760      286.308972   \n",
       "75%       148.455645       754.572841      544.886576      608.550907   \n",
       "max       533.570565      1741.885536     2010.729448     1515.122984   \n",
       "\n",
       "       contrast_d2_0  contrast_d2_135  contrast_d2_45  contrast_d2_90  \\\n",
       "count     224.000000       224.000000      224.000000      224.000000   \n",
       "mean      291.567108       481.666424      391.710732      812.619982   \n",
       "std       301.621589       409.512881      367.517034      711.742505   \n",
       "min        16.289583        25.159209       21.857440       35.629167   \n",
       "25%        90.478125       189.221904      134.213059      287.708854   \n",
       "50%       144.367708       306.805411      250.070760      511.067187   \n",
       "75%       472.954427       754.572841      544.886576     1233.457812   \n",
       "max      1349.643750      1741.885536     2010.729448     3065.783333   \n",
       "\n",
       "       contrast_d3_0  contrast_d3_135  ...  homogeneity_d2_0  \\\n",
       "count     224.000000       224.000000  ...        224.000000   \n",
       "mean      475.429606       828.227639  ...          0.107538   \n",
       "std       444.706417       735.899216  ...          0.038212   \n",
       "min        25.405172        34.073333  ...          0.039628   \n",
       "25%       160.724138       281.397222  ...          0.077724   \n",
       "50%       253.303341       518.418333  ...          0.106529   \n",
       "75%       803.068696      1244.031667  ...          0.130661   \n",
       "max      1961.033405      3096.735556  ...          0.263151   \n",
       "\n",
       "       homogeneity_d2_135  homogeneity_d2_45  homogeneity_d2_90  \\\n",
       "count          224.000000         224.000000         224.000000   \n",
       "mean             0.081329           0.094749           0.064927   \n",
       "std              0.027045           0.037523           0.025917   \n",
       "min              0.031445           0.032693           0.026174   \n",
       "25%              0.062667           0.066959           0.044854   \n",
       "50%              0.079249           0.089093           0.061241   \n",
       "75%              0.095316           0.114242           0.080179   \n",
       "max              0.222067           0.256477           0.188469   \n",
       "\n",
       "       homogeneity_d3_0  homogeneity_d3_135  homogeneity_d3_45  \\\n",
       "count        224.000000          224.000000         224.000000   \n",
       "mean           0.083671            0.065257           0.066878   \n",
       "std            0.031683            0.026520           0.026213   \n",
       "min            0.027532            0.024179           0.028836   \n",
       "25%            0.060323            0.045083           0.048439   \n",
       "50%            0.081235            0.061081           0.061561   \n",
       "75%            0.103041            0.078092           0.080720   \n",
       "max            0.223884            0.193968           0.196544   \n",
       "\n",
       "       homogeneity_d3_90        mean     variance  \n",
       "count         224.000000  224.000000   224.000000  \n",
       "mean            0.063261  118.604558   612.059621  \n",
       "std             0.026805   43.781055   519.012346  \n",
       "min             0.022595   30.594727    22.063354  \n",
       "25%             0.042672   86.614502   221.020653  \n",
       "50%             0.059077  120.194824   425.679302  \n",
       "75%             0.079175  147.738525   810.817033  \n",
       "max             0.174825  235.129883  2777.443015  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# test_images = read_images(\"dataset/stretched/test\")\n",
    "# mlp_data = build_with_mlp(test_images)\n",
    "# test_data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     test_data = test_data.append(frame)\n",
    "    \n",
    "# test_data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# test_data.to_csv(\"dataset/test.csv\")\n",
    "\n",
    "test_data = pd.read_csv('dataset/test.csv', index_col='name')\n",
    "\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fab083",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af4b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_data, drop):\n",
    "    X_train = data.copy()#.drop(['name'], axis=1)\n",
    "    y_train = X_train.pop('target')\n",
    "    X_test = test_data.copy()#.drop(['name'], axis=1)\n",
    "    y_test = X_test.pop('target')\n",
    "\n",
    "    X_train = X_train[y_train != drop]\n",
    "    X_test = X_test[y_test != drop]\n",
    "\n",
    "    y_train = y_train[y_train != drop]\n",
    "    y_test = y_test[y_test != drop]\n",
    "\n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train)\n",
    "    X_train = pd.DataFrame(std.transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "    X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    return X_train, y_train, X_test, y_test, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(model.predict(X_test),index=y_test.index)\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "261fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_pred(y_pred):\n",
    "    count = 0\n",
    "    prediction = {}\n",
    "    for name in np.unique(y_pred.index):\n",
    "        pred_cls = {}\n",
    "        for i in y_pred[name]:\n",
    "            if i not in pred_cls.keys():\n",
    "                pred_cls[i]=1\n",
    "            else: pred_cls[i]+=1\n",
    "        \n",
    "        prediction[name] = max(pred_cls, key=pred_cls.get)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93aedb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_acc(y_test, y_pred):\n",
    "    pred_count = 0\n",
    "    for key in y_pred.keys():\n",
    "        if y_test[key][0] == y_pred[key]:\n",
    "            pred_count += 1\n",
    "    return pred_count/len(y_pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0889f161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatty cirrhosis\n",
      "RFC  Image Accuracy:  0.8571428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.666667  0.633333  0.649573   60.000000\n",
      "fatty          0.770833  0.795699  0.783069   93.000000\n",
      "accuracy       0.732026  0.732026  0.732026    0.732026\n",
      "macro avg      0.718750  0.714516  0.716321  153.000000\n",
      "weighted avg   0.729984  0.732026  0.730717  153.000000\n",
      "MLP  Image Accuracy:  0.8571428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.736842  0.700000  0.717949   60.000000\n",
      "fatty          0.812500  0.838710  0.825397   93.000000\n",
      "accuracy       0.784314  0.784314  0.784314    0.784314\n",
      "macro avg      0.774671  0.769355  0.771673  153.000000\n",
      "weighted avg   0.782830  0.784314  0.783260  153.000000\n",
      "SVC  Image Accuracy:  0.8571428571428571\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.687500  0.733333  0.709677   60.000000\n",
      "fatty          0.820225  0.784946  0.802198   93.000000\n",
      "accuracy       0.764706  0.764706  0.764706    0.764706\n",
      "macro avg      0.753862  0.759140  0.755938  153.000000\n",
      "weighted avg   0.768176  0.764706  0.765915  153.000000\n",
      "\n",
      "\n",
      "\n",
      "normal cirrhosis\n",
      "RFC  Image Accuracy:  0.5\n",
      "              precision    recall  f1-score    support\n",
      "cirrhosis      0.370370  0.166667  0.229885   60.00000\n",
      "normal         0.519231  0.760563  0.617143   71.00000\n",
      "accuracy       0.488550  0.488550  0.488550    0.48855\n",
      "macro avg      0.444801  0.463615  0.423514  131.00000\n",
      "weighted avg   0.451050  0.488550  0.439773  131.00000\n",
      "MLP  Image Accuracy:  0.7\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.500000  0.433333  0.464286   60.000000\n",
      "normal         0.569620  0.633803  0.600000   71.000000\n",
      "accuracy       0.541985  0.541985  0.541985    0.541985\n",
      "macro avg      0.534810  0.533568  0.532143  131.000000\n",
      "weighted avg   0.537733  0.541985  0.537841  131.000000\n",
      "SVC  Image Accuracy:  0.5\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.406250  0.216667  0.282609   60.000000\n",
      "normal         0.525253  0.732394  0.611765   71.000000\n",
      "accuracy       0.496183  0.496183  0.496183    0.496183\n",
      "macro avg      0.465751  0.474531  0.447187  131.000000\n",
      "weighted avg   0.470748  0.496183  0.461006  131.000000\n",
      "\n",
      "\n",
      "\n",
      "normal fatty\n",
      "RFC  Image Accuracy:  0.6875\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.696629  0.666667  0.681319   93.000000\n",
      "normal         0.586667  0.619718  0.602740   71.000000\n",
      "accuracy       0.646341  0.646341  0.646341    0.646341\n",
      "macro avg      0.641648  0.643192  0.642029  164.000000\n",
      "weighted avg   0.649023  0.646341  0.647300  164.000000\n",
      "MLP  Image Accuracy:  0.8125\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.716981  0.817204  0.763819   93.000000\n",
      "normal         0.706897  0.577465  0.635659   71.000000\n",
      "accuracy       0.713415  0.713415  0.713415    0.713415\n",
      "macro avg      0.711939  0.697335  0.699739  164.000000\n",
      "weighted avg   0.712615  0.713415  0.708335  164.000000\n",
      "SVC  Image Accuracy:  0.6875\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.687500  0.709677  0.698413   93.000000\n",
      "normal         0.602941  0.577465  0.589928   71.000000\n",
      "accuracy       0.652439  0.652439  0.652439    0.652439\n",
      "macro avg      0.645221  0.643571  0.644170  164.000000\n",
      "weighted avg   0.650892  0.652439  0.651447  164.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RFC\": RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    max_features='auto',\n",
    "                    n_estimators= 500,\n",
    "                    max_depth=6,\n",
    "                    criterion='entropy'),\n",
    "    \"MLP\": MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001),\n",
    "    \"SVC\": svm.SVC()\n",
    "}\n",
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "\n",
    "for drop in classes:\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop)\n",
    "    print(*[cls for cls in classes if cls != drop])\n",
    "    for name in models.keys():\n",
    "        model, y_pred = train_test(models[name], X_train, y_train, X_test, y_test)\n",
    "        prediction = images_pred(y_pred)\n",
    "        print(name,\" Image Accuracy: \", images_acc(y_test, prediction))\n",
    "        report = classification_report(y_test, y_pred, output_dict = True)\n",
    "        cr = pd.DataFrame(report).transpose()\n",
    "        print(cr)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96b60ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Fatty MLP Image Accuracy:  0.8125\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.732673  0.795699  0.762887   93.000000\n",
      "normal         0.698413  0.619718  0.656716   71.000000\n",
      "accuracy       0.719512  0.719512  0.719512    0.719512\n",
      "macro avg      0.715543  0.707709  0.709802  164.000000\n",
      "weighted avg   0.717841  0.719512  0.716923  164.000000\n"
     ]
    }
   ],
   "source": [
    "normal_fatty_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "X_train, y_train, X_test, y_test, normal_fatty_std = split(data, test_data, 'cirrhosis')\n",
    "model, y_pred = train_test(normal_fatty_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_fatty_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30cbeaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal/cirrhosis MLP Image Accuracy:  0.7\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.500000  0.466667  0.482759   60.000000\n",
      "normal         0.573333  0.605634  0.589041   71.000000\n",
      "accuracy       0.541985  0.541985  0.541985    0.541985\n",
      "macro avg      0.536667  0.536150  0.535900  131.000000\n",
      "weighted avg   0.539746  0.541985  0.540362  131.000000\n"
     ]
    }
   ],
   "source": [
    "normal_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "X_train, y_train, X_test, y_test, normal_cirrhosis_std = split(data, test_data, 'fatty')\n",
    "model, y_pred = train_test(normal_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "normal_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"normal/cirrhosis MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67e2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cirrhosis/Fatty MLP Image Accuracy:  1.0\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.765625  0.816667  0.790323   60.000000\n",
      "fatty          0.876404  0.838710  0.857143   93.000000\n",
      "accuracy       0.830065  0.830065  0.830065    0.830065\n",
      "macro avg      0.821015  0.827688  0.823733  153.000000\n",
      "weighted avg   0.832962  0.830065  0.830939  153.000000\n"
     ]
    }
   ],
   "source": [
    "fatty_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "X_train, y_train, X_test, y_test, fatty_cirrhosis_std = split(data, test_data, 'normal')\n",
    "model, y_pred = train_test(fatty_cirrhosis_mlp, X_train, y_train, X_test, y_test)\n",
    "fatty_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "341e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"normal_fatty\": (normal_fatty_mlp, normal_fatty_std),\n",
    "    \"normal_cirrhosis\": (normal_cirrhosis_mlp, normal_cirrhosis_std),\n",
    "    \"fatty_cirrhosis\": (fatty_cirrhosis_mlp, fatty_cirrhosis_std)\n",
    "}\n",
    "\n",
    "X_test = test_data.copy()\n",
    "y_test = X_test.pop('target')\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52782718",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "predictions = {}\n",
    "for name in models.keys():\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "    X_test = pd.DataFrame(models[name][1].transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    y_pred = pd.Series(models[name][0].predict(X_test),index=y_test.index)\n",
    "    predictions[name] = images_pred(y_pred)\n",
    "    \n",
    "image_names = np.unique(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebd475fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = np.unique(y_test.index)\n",
    "final_pred = {}\n",
    "for image in image_name:\n",
    "    pred = {\n",
    "        'normal': 0,\n",
    "        'fatty': 0,\n",
    "        'cirrhosis': 0\n",
    "    }\n",
    "    for model in predictions.keys():\n",
    "        pred[predictions[model][image]] += 1\n",
    "    cls = max(pred, key=pred.get)\n",
    "    if pred[cls] == 1:\n",
    "        final_pred[image] = 'abstain'\n",
    "    else: final_pred[image] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2387b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_acc(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "424c72bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "cirrhosis      0.666667  0.500000  0.571429   4.000000\n",
      "fatty          0.900000  1.000000  0.947368   9.000000\n",
      "normal         0.666667  0.666667  0.666667   6.000000\n",
      "accuracy       0.789474  0.789474  0.789474   0.789474\n",
      "macro avg      0.744444  0.722222  0.728488  19.000000\n",
      "weighted avg   0.777193  0.789474  0.779581  19.000000\n",
      "Abstension Rate:  0.05\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test[~y_test.index.duplicated(keep='first')].sort_index()\n",
    "y_pred = pd.Series(final_pred).sort_index()\n",
    "abstain = y_pred[y_pred=='abstain'].index\n",
    "\n",
    "y_test = y_test.drop(abstain)\n",
    "y_pred = y_pred.drop(abstain)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)\n",
    "print(\"Abstension Rate: \", len(abstain)/(len(y_pred)+len(abstain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "067118c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "for name in models.keys():\n",
    "    dump(models[name][0], f'dataset/models/{name}_mlp.joblib') \n",
    "    dump(models[name][1], f'dataset/models/{name}_std.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
