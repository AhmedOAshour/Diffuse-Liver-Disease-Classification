{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5bb83d",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5de7e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv\n",
    "import SimpleITK as sitk\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import greycomatrix\n",
    "from skimage.feature.texture import greycoprops\n",
    "from skimage.measure import shannon_entropy\n",
    "from radiomics import glrlm, glcm\n",
    "# import pyfeats\n",
    "import pandas as pd\n",
    "import multiprocessing as mlp\n",
    "import math\n",
    "import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dcb13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe50bfe",
   "metadata": {},
   "source": [
    "## Define Feature Extraction functions\n",
    "\n",
    "### Read dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357d0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder = \"dataset/train\",\n",
    "                classes = [\n",
    "                            \"normal\",\n",
    "                            \"fatty\",\n",
    "                            \"cirrhosis\"\n",
    "                        ]):\n",
    "    image_names = {}\n",
    "    images = []\n",
    "    # Get all image names in folders\n",
    "    for cls in classes:\n",
    "        image_names[cls] = os.listdir(f'{folder}/{cls}')\n",
    "\n",
    "    # read all images to list\n",
    "    for cls in classes:\n",
    "        for name in image_names[cls]:\n",
    "            mask = []\n",
    "            with open(f'dataset/masks/{name[0:-4]}.txt', 'r') as file:\n",
    "                data = file.read()\n",
    "                data = data.strip().split('\\n')\n",
    "                for line in data:\n",
    "                    x, y = line.split(',')\n",
    "                    mask.append((int(y),int(x)))\n",
    "            img = sitk.ReadImage(f'{folder}/{cls}/{name}', sitk.sitkUInt8)\n",
    "            images.append((name, img,cls,mask))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda0a6a1",
   "metadata": {},
   "source": [
    "### Extract ROIs from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4160da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_roi(img, start , size = (32,32)):\n",
    "    img = sitk.GetArrayFromImage(img)\n",
    "    roi = img[start[0]:start[0]+size[0],start[1]:start[1]+size[1]]\n",
    "    mask = np.zeros(img.shape)\n",
    "    mask[start[0]:start[0]+size[0],start[1]:start[1]+size[1]] = 1\n",
    "    return roi, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51daa8a",
   "metadata": {},
   "source": [
    "### Extract Features from ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd4402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img, roi_pos):\n",
    "    roi_mask_arr = []\n",
    "    for pos in roi_pos:\n",
    "        roi_mask_arr.append(extract_roi(img, pos))\n",
    "    \n",
    "    # 0 45 90 135 degrees\n",
    "    angles = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
    "    \n",
    "    da_dict = {\n",
    "        0: \"d1_0\",\n",
    "        1: \"d1_45\",\n",
    "        2: \"d1_90\",\n",
    "        3: \"d1_135\",\n",
    "        \n",
    "        4: \"d2_0\",\n",
    "        5: \"d2_45\",\n",
    "        6: \"d2_90\",\n",
    "        7: \"d2_135\",\n",
    "        \n",
    "        8: \"d3_0\",\n",
    "        9: \"d3_45\",\n",
    "        10: \"d3_90\",\n",
    "        11: \"d3_135\",\n",
    "        \n",
    "    }\n",
    "    \n",
    "    feat_arr = []\n",
    "    for roi, mask in roi_mask_arr:\n",
    "        features = {}\n",
    "        \n",
    "        glcm_mtx = greycomatrix(roi, distances = [1,2,3], angles = angles, levels = 256)\n",
    "        con = greycoprops(glcm_mtx, 'contrast').flatten()\n",
    "        hom = greycoprops(glcm_mtx, 'homogeneity').flatten()\n",
    "        en = greycoprops(glcm_mtx, 'energy').flatten()\n",
    "        corr = greycoprops(glcm_mtx, 'correlation').flatten()\n",
    "        \n",
    "        for j in range(len(da_dict)):\n",
    "            features[f'contrast_{da_dict[j]}'] = con[j]\n",
    "            features[f'homogeneity_{da_dict[j]}'] = hom[j]\n",
    "            features[f'energy_{da_dict[j]}'] = en[j]\n",
    "            features[f'correlation_{da_dict[j]}'] = corr[j]\n",
    "            \n",
    "        features[f'entropy'] = shannon_entropy(roi)\n",
    "        \n",
    "        features[f'mean'] = np.mean(roi)\n",
    "        features[f'variance'] = np.var(roi)\n",
    "        \n",
    "        # pyradiomics\n",
    "        mask = sitk.GetImageFromArray(mask)\n",
    "        # GLCM features\n",
    "        glcmFeatures = glcm.RadiomicsGLCM(img, mask)\n",
    "        glcmFeatures.enableAllFeatures()\n",
    "        results = glcmFeatures.execute()\n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        \n",
    "        # GLRLM features\n",
    "        glrlmFeatures = glrlm.RadiomicsGLRLM(img, mask)\n",
    "        glrlmFeatures.enableAllFeatures()\n",
    "        results = glrlmFeatures.execute()\n",
    "        \n",
    "        for col in results.keys():\n",
    "            features[col] = results[col].item()\n",
    "        \n",
    "        feat_arr.append(features)\n",
    "        \n",
    "    return feat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486a2d3",
   "metadata": {},
   "source": [
    "### Construct dataframe from ROI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0f2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframe(images):\n",
    "    # dataframe consists of features of 1 ROI per image\n",
    "    # column name roiNum_feature\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    for img, cls, mask in images:\n",
    "        feat_arr = feature_extraction(img, roi_pos=mask)\n",
    "        for row in feat_arr:\n",
    "            row['target'] = cls\n",
    "            data = data.append(row,ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c31aa7",
   "metadata": {},
   "source": [
    "### Construct dataframe using multiprocessing\n",
    "### Reduced runtime by 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f1592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_with_mlp(images, n=9): \n",
    "    pool = mlp.Pool(n)\n",
    "    results = pool.map(fe.build_dataframe,np.array_split(images,n))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639b10c",
   "metadata": {},
   "source": [
    "## Feature Analysis and Selection\n",
    "\n",
    "### Extract Features and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f03422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 209 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d1_45</th>\n",
       "      <th>homogeneity_d1_90</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1.875000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.607947</td>\n",
       "      <td>78.450133</td>\n",
       "      <td>5.265885</td>\n",
       "      <td>6.796472</td>\n",
       "      <td>0.534181</td>\n",
       "      <td>1.057417</td>\n",
       "      <td>0.273418</td>\n",
       "      <td>0.536117</td>\n",
       "      <td>0.254731</td>\n",
       "      <td>7.737835e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169810</td>\n",
       "      <td>0.163014</td>\n",
       "      <td>0.188472</td>\n",
       "      <td>0.151202</td>\n",
       "      <td>0.169810</td>\n",
       "      <td>0.118795</td>\n",
       "      <td>0.148841</td>\n",
       "      <td>0.117156</td>\n",
       "      <td>0.123361</td>\n",
       "      <td>0.113331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.157389</td>\n",
       "      <td>27.822747</td>\n",
       "      <td>2.935076</td>\n",
       "      <td>18.132138</td>\n",
       "      <td>1.969909</td>\n",
       "      <td>0.894590</td>\n",
       "      <td>0.149987</td>\n",
       "      <td>0.148141</td>\n",
       "      <td>0.124245</td>\n",
       "      <td>2.413614e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>0.067913</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>0.064099</td>\n",
       "      <td>0.074271</td>\n",
       "      <td>0.053416</td>\n",
       "      <td>0.068449</td>\n",
       "      <td>0.053321</td>\n",
       "      <td>0.055464</td>\n",
       "      <td>0.053904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.367119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044883</td>\n",
       "      <td>0.055994</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.044883</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.035131</td>\n",
       "      <td>0.036691</td>\n",
       "      <td>0.031642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>58.700000</td>\n",
       "      <td>3.249825</td>\n",
       "      <td>0.909022</td>\n",
       "      <td>-0.106256</td>\n",
       "      <td>0.569849</td>\n",
       "      <td>0.166310</td>\n",
       "      <td>0.437385</td>\n",
       "      <td>0.164957</td>\n",
       "      <td>6.338971e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115812</td>\n",
       "      <td>0.105677</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>0.100899</td>\n",
       "      <td>0.115812</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>0.093532</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.070858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>79.700000</td>\n",
       "      <td>4.539973</td>\n",
       "      <td>2.138432</td>\n",
       "      <td>0.153262</td>\n",
       "      <td>0.833975</td>\n",
       "      <td>0.235635</td>\n",
       "      <td>0.525369</td>\n",
       "      <td>0.231164</td>\n",
       "      <td>7.685916e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161081</td>\n",
       "      <td>0.158151</td>\n",
       "      <td>0.188360</td>\n",
       "      <td>0.146820</td>\n",
       "      <td>0.161081</td>\n",
       "      <td>0.113689</td>\n",
       "      <td>0.147429</td>\n",
       "      <td>0.111746</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.106542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>6.776047</td>\n",
       "      <td>5.294571</td>\n",
       "      <td>0.474892</td>\n",
       "      <td>1.276992</td>\n",
       "      <td>0.379435</td>\n",
       "      <td>0.634107</td>\n",
       "      <td>0.352453</td>\n",
       "      <td>9.597778e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.196115</td>\n",
       "      <td>0.233789</td>\n",
       "      <td>0.184354</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>0.145168</td>\n",
       "      <td>0.183088</td>\n",
       "      <td>0.142910</td>\n",
       "      <td>0.149219</td>\n",
       "      <td>0.139533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>21.507170</td>\n",
       "      <td>444.720620</td>\n",
       "      <td>34.921036</td>\n",
       "      <td>13.172388</td>\n",
       "      <td>0.877211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596986</td>\n",
       "      <td>1.343032e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775769</td>\n",
       "      <td>0.743040</td>\n",
       "      <td>0.741631</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.775769</td>\n",
       "      <td>0.673950</td>\n",
       "      <td>0.697514</td>\n",
       "      <td>0.620327</td>\n",
       "      <td>0.699876</td>\n",
       "      <td>0.623982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count   1875.000000   1875.000000      1875.000000        1875.000000   \n",
       "mean      49.607947     78.450133         5.265885           6.796472   \n",
       "std       22.157389     27.822747         2.935076          18.132138   \n",
       "min        0.000000      6.000000         1.000000           0.000000   \n",
       "25%       34.000000     58.700000         3.249825           0.909022   \n",
       "50%       49.000000     79.700000         4.539973           2.138432   \n",
       "75%       64.000000     98.000000         6.776047           5.294571   \n",
       "max      132.000000    170.000000        21.507170         444.720620   \n",
       "\n",
       "       ClusterShade  ClusterTendency     Contrast  Correlation  \\\n",
       "count   1875.000000      1875.000000  1875.000000  1875.000000   \n",
       "mean       0.534181         1.057417     0.273418     0.536117   \n",
       "std        1.969909         0.894590     0.149987     0.148141   \n",
       "min       -8.367119         0.000000     0.000000    -0.002694   \n",
       "25%       -0.106256         0.569849     0.166310     0.437385   \n",
       "50%        0.153262         0.833975     0.235635     0.525369   \n",
       "75%        0.474892         1.276992     0.379435     0.634107   \n",
       "max       34.921036        13.172388     0.877211     1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d1_45  \\\n",
       "count        1875.000000       1.875000e+03  ...        1875.000000   \n",
       "mean            0.254731       7.737835e-01  ...           0.169810   \n",
       "std             0.124245       2.413614e-01  ...           0.074271   \n",
       "min             0.000000      -3.203427e-16  ...           0.044883   \n",
       "25%             0.164957       6.338971e-01  ...           0.115812   \n",
       "50%             0.231164       7.685916e-01  ...           0.161081   \n",
       "75%             0.352453       9.597778e-01  ...           0.205439   \n",
       "max             0.596986       1.343032e+00  ...           0.775769   \n",
       "\n",
       "       homogeneity_d1_90  homogeneity_d2_0  homogeneity_d2_135  \\\n",
       "count        1875.000000       1875.000000         1875.000000   \n",
       "mean            0.163014          0.188472            0.151202   \n",
       "std             0.067913          0.084368            0.064099   \n",
       "min             0.055994          0.049637            0.048944   \n",
       "25%             0.105677          0.121571            0.100899   \n",
       "50%             0.158151          0.188360            0.146820   \n",
       "75%             0.196115          0.233789            0.184354   \n",
       "max             0.743040          0.741631            0.701923   \n",
       "\n",
       "       homogeneity_d2_45  homogeneity_d2_90  homogeneity_d3_0  \\\n",
       "count        1875.000000        1875.000000       1875.000000   \n",
       "mean            0.169810           0.118795          0.148841   \n",
       "std             0.074271           0.053416          0.068449   \n",
       "min             0.044883           0.030550          0.041362   \n",
       "25%             0.115812           0.075160          0.093532   \n",
       "50%             0.161081           0.113689          0.147429   \n",
       "75%             0.205439           0.145168          0.183088   \n",
       "max             0.775769           0.673950          0.697514   \n",
       "\n",
       "       homogeneity_d3_135  homogeneity_d3_45  homogeneity_d3_90  \n",
       "count         1875.000000        1875.000000        1875.000000  \n",
       "mean             0.117156           0.123361           0.113331  \n",
       "std              0.053321           0.055464           0.053904  \n",
       "min              0.035131           0.036691           0.031642  \n",
       "25%              0.075949           0.081603           0.070858  \n",
       "50%              0.111746           0.117534           0.106542  \n",
       "75%              0.142910           0.149219           0.139533  \n",
       "max              0.620327           0.699876           0.623982  \n",
       "\n",
       "[8 rows x 107 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# images = read_images('dataset/train')\n",
    "# mlp_data = build_with_mlp(images)\n",
    "# data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     data = data.append(frame)\n",
    "\n",
    "# data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# data.to_csv(\"dataset/train.csv\")\n",
    "\n",
    "data = pd.read_csv('dataset/train.csv', index_col='name')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cba1dff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 134 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10Percentile</th>\n",
       "      <th>90Percentile</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>ClusterProminence</th>\n",
       "      <th>ClusterShade</th>\n",
       "      <th>ClusterTendency</th>\n",
       "      <th>Contrast</th>\n",
       "      <th>Correlation</th>\n",
       "      <th>DifferenceAverage</th>\n",
       "      <th>DifferenceEntropy</th>\n",
       "      <th>...</th>\n",
       "      <th>homogeneity_d1_45</th>\n",
       "      <th>homogeneity_d1_90</th>\n",
       "      <th>homogeneity_d2_0</th>\n",
       "      <th>homogeneity_d2_135</th>\n",
       "      <th>homogeneity_d2_45</th>\n",
       "      <th>homogeneity_d2_90</th>\n",
       "      <th>homogeneity_d3_0</th>\n",
       "      <th>homogeneity_d3_135</th>\n",
       "      <th>homogeneity_d3_45</th>\n",
       "      <th>homogeneity_d3_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.00000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>3.820000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.217277</td>\n",
       "      <td>79.27644</td>\n",
       "      <td>5.295707</td>\n",
       "      <td>7.244694</td>\n",
       "      <td>0.579809</td>\n",
       "      <td>1.082905</td>\n",
       "      <td>0.261253</td>\n",
       "      <td>0.554878</td>\n",
       "      <td>0.244751</td>\n",
       "      <td>7.640925e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176052</td>\n",
       "      <td>0.164242</td>\n",
       "      <td>0.185952</td>\n",
       "      <td>0.147653</td>\n",
       "      <td>0.176052</td>\n",
       "      <td>0.120195</td>\n",
       "      <td>0.146332</td>\n",
       "      <td>0.117783</td>\n",
       "      <td>0.125761</td>\n",
       "      <td>0.115112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.434761</td>\n",
       "      <td>27.34130</td>\n",
       "      <td>2.853370</td>\n",
       "      <td>17.294010</td>\n",
       "      <td>2.246493</td>\n",
       "      <td>0.853788</td>\n",
       "      <td>0.137671</td>\n",
       "      <td>0.145262</td>\n",
       "      <td>0.113077</td>\n",
       "      <td>2.203017e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073037</td>\n",
       "      <td>0.064448</td>\n",
       "      <td>0.073204</td>\n",
       "      <td>0.056312</td>\n",
       "      <td>0.073037</td>\n",
       "      <td>0.051804</td>\n",
       "      <td>0.059865</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.054049</td>\n",
       "      <td>0.051733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.508871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.203427e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.063136</td>\n",
       "      <td>0.057985</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.031740</td>\n",
       "      <td>0.046913</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.039154</td>\n",
       "      <td>0.034577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>60.25000</td>\n",
       "      <td>3.509715</td>\n",
       "      <td>0.894214</td>\n",
       "      <td>-0.104566</td>\n",
       "      <td>0.552214</td>\n",
       "      <td>0.167227</td>\n",
       "      <td>0.451109</td>\n",
       "      <td>0.164111</td>\n",
       "      <td>6.380821e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124869</td>\n",
       "      <td>0.114571</td>\n",
       "      <td>0.124603</td>\n",
       "      <td>0.108026</td>\n",
       "      <td>0.124869</td>\n",
       "      <td>0.082521</td>\n",
       "      <td>0.099154</td>\n",
       "      <td>0.079586</td>\n",
       "      <td>0.089632</td>\n",
       "      <td>0.077233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>4.721010</td>\n",
       "      <td>2.237011</td>\n",
       "      <td>0.208912</td>\n",
       "      <td>0.825854</td>\n",
       "      <td>0.227071</td>\n",
       "      <td>0.552495</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>7.549453e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165739</td>\n",
       "      <td>0.161493</td>\n",
       "      <td>0.183858</td>\n",
       "      <td>0.147430</td>\n",
       "      <td>0.165739</td>\n",
       "      <td>0.115742</td>\n",
       "      <td>0.140288</td>\n",
       "      <td>0.111879</td>\n",
       "      <td>0.118271</td>\n",
       "      <td>0.107708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>97.00000</td>\n",
       "      <td>6.858440</td>\n",
       "      <td>6.281702</td>\n",
       "      <td>0.529058</td>\n",
       "      <td>1.381738</td>\n",
       "      <td>0.343392</td>\n",
       "      <td>0.654871</td>\n",
       "      <td>0.322666</td>\n",
       "      <td>9.290920e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213714</td>\n",
       "      <td>0.198065</td>\n",
       "      <td>0.232590</td>\n",
       "      <td>0.176334</td>\n",
       "      <td>0.213714</td>\n",
       "      <td>0.144507</td>\n",
       "      <td>0.179333</td>\n",
       "      <td>0.136750</td>\n",
       "      <td>0.148503</td>\n",
       "      <td>0.135590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>150.00000</td>\n",
       "      <td>16.215100</td>\n",
       "      <td>218.165215</td>\n",
       "      <td>27.204337</td>\n",
       "      <td>6.577641</td>\n",
       "      <td>0.748138</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577532</td>\n",
       "      <td>1.288810e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601422</td>\n",
       "      <td>0.594621</td>\n",
       "      <td>0.567898</td>\n",
       "      <td>0.533208</td>\n",
       "      <td>0.601422</td>\n",
       "      <td>0.451463</td>\n",
       "      <td>0.487847</td>\n",
       "      <td>0.414726</td>\n",
       "      <td>0.481178</td>\n",
       "      <td>0.408715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10Percentile  90Percentile  Autocorrelation  ClusterProminence  \\\n",
       "count    382.000000     382.00000       382.000000         382.000000   \n",
       "mean      50.217277      79.27644         5.295707           7.244694   \n",
       "std       22.434761      27.34130         2.853370          17.294010   \n",
       "min        1.000000       7.00000         1.000000           0.000000   \n",
       "25%       35.000000      60.25000         3.509715           0.894214   \n",
       "50%       50.000000      80.00000         4.721010           2.237011   \n",
       "75%       62.000000      97.00000         6.858440           6.281702   \n",
       "max      128.000000     150.00000        16.215100         218.165215   \n",
       "\n",
       "       ClusterShade  ClusterTendency    Contrast  Correlation  \\\n",
       "count    382.000000       382.000000  382.000000   382.000000   \n",
       "mean       0.579809         1.082905    0.261253     0.554878   \n",
       "std        2.246493         0.853788    0.137671     0.145262   \n",
       "min       -3.508871         0.000000    0.000000    -0.000639   \n",
       "25%       -0.104566         0.552214    0.167227     0.451109   \n",
       "50%        0.208912         0.825854    0.227071     0.552495   \n",
       "75%        0.529058         1.381738    0.343392     0.654871   \n",
       "max       27.204337         6.577641    0.748138     1.000000   \n",
       "\n",
       "       DifferenceAverage  DifferenceEntropy  ...  homogeneity_d1_45  \\\n",
       "count         382.000000       3.820000e+02  ...         382.000000   \n",
       "mean            0.244751       7.640925e-01  ...           0.176052   \n",
       "std             0.113077       2.203017e-01  ...           0.073037   \n",
       "min             0.000000      -3.203427e-16  ...           0.055655   \n",
       "25%             0.164111       6.380821e-01  ...           0.124869   \n",
       "50%             0.223359       7.549453e-01  ...           0.165739   \n",
       "75%             0.322666       9.290920e-01  ...           0.213714   \n",
       "max             0.577532       1.288810e+00  ...           0.601422   \n",
       "\n",
       "       homogeneity_d1_90  homogeneity_d2_0  homogeneity_d2_135  \\\n",
       "count         382.000000        382.000000          382.000000   \n",
       "mean            0.164242          0.185952            0.147653   \n",
       "std             0.064448          0.073204            0.056312   \n",
       "min             0.066152          0.063136            0.057985   \n",
       "25%             0.114571          0.124603            0.108026   \n",
       "50%             0.161493          0.183858            0.147430   \n",
       "75%             0.198065          0.232590            0.176334   \n",
       "max             0.594621          0.567898            0.533208   \n",
       "\n",
       "       homogeneity_d2_45  homogeneity_d2_90  homogeneity_d3_0  \\\n",
       "count         382.000000         382.000000        382.000000   \n",
       "mean            0.176052           0.120195          0.146332   \n",
       "std             0.073037           0.051804          0.059865   \n",
       "min             0.055655           0.031740          0.046913   \n",
       "25%             0.124869           0.082521          0.099154   \n",
       "50%             0.165739           0.115742          0.140288   \n",
       "75%             0.213714           0.144507          0.179333   \n",
       "max             0.601422           0.451463          0.487847   \n",
       "\n",
       "       homogeneity_d3_135  homogeneity_d3_45  homogeneity_d3_90  \n",
       "count          382.000000         382.000000         382.000000  \n",
       "mean             0.117783           0.125761           0.115112  \n",
       "std              0.051189           0.054049           0.051733  \n",
       "min              0.037576           0.039154           0.034577  \n",
       "25%              0.079586           0.089632           0.077233  \n",
       "50%              0.111879           0.118271           0.107708  \n",
       "75%              0.136750           0.148503           0.135590  \n",
       "max              0.414726           0.481178           0.408715  \n",
       "\n",
       "[8 rows x 107 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# test_images = read_images(\"dataset/test\")\n",
    "# mlp_data = build_with_mlp(test_images)\n",
    "# test_data = pd.DataFrame()\n",
    "# for frame in mlp_data:\n",
    "#     test_data = test_data.append(frame)\n",
    "    \n",
    "# test_data.set_index('name', drop=True, inplace=True)\n",
    "\n",
    "# test_data.to_csv(\"dataset/test.csv\")\n",
    "\n",
    "test_data = pd.read_csv('dataset/test.csv', index_col='name')\n",
    "\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fab083",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af4b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_data, drop):\n",
    "    X_train = data.copy()#.drop(['name'], axis=1)\n",
    "    y_train = X_train.pop('target')\n",
    "    X_test = test_data.copy()#.drop(['name'], axis=1)\n",
    "    y_test = X_test.pop('target')\n",
    "\n",
    "    X_train = X_train[y_train != drop]\n",
    "    X_test = X_test[y_test != drop]\n",
    "\n",
    "    y_train = y_train[y_train != drop]\n",
    "    y_test = y_test[y_test != drop]\n",
    "\n",
    "    std = StandardScaler()\n",
    "    std.fit(X_train)\n",
    "    X_train = pd.DataFrame(std.transform(X_train), columns = X_train.columns, index = X_train.index)\n",
    "    X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    return X_train, y_train, X_test, y_test, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de6d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, X_train, y_train, X_test, y_test):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = pd.Series(model.predict(X_test),index=y_test.index)\n",
    "    return model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "261fde3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_pred(y_pred):\n",
    "    count = 0\n",
    "    prediction = {}\n",
    "    for name in np.unique(y_pred.index):\n",
    "        pred_cls = {}\n",
    "        for i in y_pred[name]:\n",
    "            if i not in pred_cls.keys():\n",
    "                pred_cls[i]=1\n",
    "            else: pred_cls[i]+=1\n",
    "        \n",
    "        prediction[name] = max(pred_cls, key=pred_cls.get)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93aedb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_acc(y_test, y_pred):\n",
    "    pred_count = 0\n",
    "    for key in y_pred.keys():\n",
    "        if y_test[key][0] == y_pred[key]:\n",
    "            pred_count += 1\n",
    "    return pred_count/len(y_pred.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0889f161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatty cirrhosis\n",
      "RFC  Image Accuracy:  0.8181818181818182\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.857143  0.461538  0.600000   78.000000\n",
      "fatty          0.780105  0.961290  0.861272  155.000000\n",
      "accuracy       0.793991  0.793991  0.793991    0.793991\n",
      "macro avg      0.818624  0.711414  0.730636  233.000000\n",
      "weighted avg   0.805894  0.793991  0.773807  233.000000\n",
      "MLP  Image Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.704918  0.551282  0.618705   78.000000\n",
      "fatty          0.796512  0.883871  0.837920  155.000000\n",
      "accuracy       0.772532  0.772532  0.772532    0.772532\n",
      "macro avg      0.750715  0.717577  0.728313  233.000000\n",
      "weighted avg   0.765849  0.772532  0.764535  233.000000\n",
      "SVC  Image Accuracy:  0.8636363636363636\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.812500  0.500000  0.619048   78.000000\n",
      "fatty          0.789189  0.941935  0.858824  155.000000\n",
      "accuracy       0.793991  0.793991  0.793991    0.793991\n",
      "macro avg      0.800845  0.720968  0.738936  233.000000\n",
      "weighted avg   0.796993  0.793991  0.778555  233.000000\n",
      "\n",
      "\n",
      "\n",
      "normal cirrhosis\n",
      "RFC  Image Accuracy:  0.6842105263157895\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.428571  0.076923  0.130435   78.000000\n",
      "normal         0.661972  0.946309  0.779006  149.000000\n",
      "accuracy       0.647577  0.647577  0.647577    0.647577\n",
      "macro avg      0.545272  0.511616  0.454720  227.000000\n",
      "weighted avg   0.581773  0.647577  0.556149  227.000000\n",
      "MLP  Image Accuracy:  0.7368421052631579\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.575000  0.294872  0.389831   78.000000\n",
      "normal         0.705882  0.885906  0.785714  149.000000\n",
      "accuracy       0.682819  0.682819  0.682819    0.682819\n",
      "macro avg      0.640441  0.590389  0.587772  227.000000\n",
      "weighted avg   0.660910  0.682819  0.649684  227.000000\n",
      "SVC  Image Accuracy:  0.6842105263157895\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.555556  0.192308  0.285714   78.000000\n",
      "normal         0.685000  0.919463  0.785100  149.000000\n",
      "accuracy       0.669604  0.669604  0.669604    0.669604\n",
      "macro avg      0.620278  0.555885  0.535407  227.000000\n",
      "weighted avg   0.640521  0.669604  0.613505  227.000000\n",
      "\n",
      "\n",
      "\n",
      "normal fatty\n",
      "RFC  Image Accuracy:  0.7586206896551724\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.709302  0.787097  0.746177  155.000000\n",
      "normal         0.750000  0.664430  0.704626  149.000000\n",
      "accuracy       0.726974  0.726974  0.726974    0.726974\n",
      "macro avg      0.729651  0.725763  0.725402  304.000000\n",
      "weighted avg   0.729250  0.726974  0.725812  304.000000\n",
      "MLP  Image Accuracy:  0.6896551724137931\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.643275  0.709677  0.674847  155.000000\n",
      "normal         0.661654  0.590604  0.624113  149.000000\n",
      "accuracy       0.651316  0.651316  0.651316    0.651316\n",
      "macro avg      0.652464  0.650141  0.649480  304.000000\n",
      "weighted avg   0.652283  0.651316  0.649981  304.000000\n",
      "SVC  Image Accuracy:  0.6551724137931034\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.637306  0.793548  0.706897  155.000000\n",
      "normal         0.711712  0.530201  0.607692  149.000000\n",
      "accuracy       0.664474  0.664474  0.664474    0.664474\n",
      "macro avg      0.674509  0.661875  0.657294  304.000000\n",
      "weighted avg   0.673774  0.664474  0.658273  304.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"RFC\": RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    max_features='auto',\n",
    "                    n_estimators= 500,\n",
    "                    max_depth=6,\n",
    "                    criterion='entropy'),\n",
    "    \"MLP\": MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001),\n",
    "    \"SVC\": svm.SVC()\n",
    "}\n",
    "classes = ['normal', 'fatty', 'cirrhosis']\n",
    "\n",
    "for drop in classes:\n",
    "    X_train, y_train, X_test, y_test, std = split(data, test_data, drop)\n",
    "    print(*[cls for cls in classes if cls != drop])\n",
    "    for name in models.keys():\n",
    "        model, y_pred = train_test(models[name], X_train, y_train, X_test, y_test)\n",
    "        prediction = images_pred(y_pred)\n",
    "        print(name,\" Image Accuracy: \", images_acc(y_test, prediction))\n",
    "        report = classification_report(y_test, y_pred, output_dict = True)\n",
    "        cr = pd.DataFrame(report).transpose()\n",
    "        print(cr)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38fb4cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat importance\n",
    "files = ['fatty_normal', 'cirrhosis_fatty', 'cirrhosis_normal']\n",
    "features_acc={}\n",
    "for name in files:\n",
    "    features_acc[name] = pd.read_csv(f'dataset/manual selection/{name}.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "96b60ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal/Fatty MLP Image Accuracy:  0.8275862068965517\n",
      "              precision    recall  f1-score     support\n",
      "fatty          0.716763  0.800000  0.756098  155.000000\n",
      "normal         0.763359  0.671141  0.714286  149.000000\n",
      "accuracy       0.736842  0.736842  0.736842    0.736842\n",
      "macro avg      0.740061  0.735570  0.735192  304.000000\n",
      "weighted avg   0.739601  0.736842  0.735604  304.000000\n"
     ]
    }
   ],
   "source": [
    "normal_fatty_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "\n",
    "feat_imp = features_acc['fatty_normal']['ANN Accuracy'].sort_values(ascending=False)\n",
    "normal_fatty_cols = feat_imp.index[0:21]\n",
    "\n",
    "X_train, y_train, X_test, y_test, normal_fatty_std = split(data, test_data, 'cirrhosis')\n",
    "model, y_pred = train_test(normal_fatty_mlp, X_train[normal_fatty_cols], y_train, X_test[normal_fatty_cols], y_test)\n",
    "normal_fatty_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"Normal/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "30cbeaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal/cirrhosis MLP Image Accuracy:  0.7894736842105263\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.933333  0.358974  0.518519   78.000000\n",
      "normal         0.746193  0.986577  0.849711  149.000000\n",
      "accuracy       0.770925  0.770925  0.770925    0.770925\n",
      "macro avg      0.839763  0.672776  0.684115  227.000000\n",
      "weighted avg   0.810497  0.770925  0.735909  227.000000\n"
     ]
    }
   ],
   "source": [
    "normal_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "\n",
    "feat_imp = features_acc['cirrhosis_normal']['ANN Accuracy'].sort_values(ascending=False)\n",
    "normal_cirrhosis_cols = feat_imp.index[0:6]\n",
    "\n",
    "X_train, y_train, X_test, y_test, normal_cirrhosis_std = split(data, test_data, 'fatty')\n",
    "model, y_pred = train_test(normal_cirrhosis_mlp, X_train[normal_cirrhosis_cols], y_train, X_test[normal_cirrhosis_cols], y_test)\n",
    "normal_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"normal/cirrhosis MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b67e2656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cirrhosis/Fatty MLP Image Accuracy:  0.9545454545454546\n",
      "              precision    recall  f1-score     support\n",
      "cirrhosis      0.784615  0.653846  0.713287   78.000000\n",
      "fatty          0.839286  0.909677  0.873065  155.000000\n",
      "accuracy       0.824034  0.824034  0.824034    0.824034\n",
      "macro avg      0.811951  0.781762  0.793176  233.000000\n",
      "weighted avg   0.820984  0.824034  0.819577  233.000000\n"
     ]
    }
   ],
   "source": [
    "fatty_cirrhosis_mlp = MLPClassifier(\n",
    "                    max_iter=600,\n",
    "                    momentum=0.6,\n",
    "                    solver='adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init=0.005,\n",
    "                    alpha=0.001)\n",
    "\n",
    "feat_imp = features_acc['cirrhosis_fatty']['ANN Accuracy'].sort_values(ascending=False)\n",
    "fatty_cirrhosis_cols = feat_imp.index[0:82]\n",
    "\n",
    "X_train, y_train, X_test, y_test, fatty_cirrhosis_std = split(data, test_data, 'normal')\n",
    "model, y_pred = train_test(fatty_cirrhosis_mlp, X_train[fatty_cirrhosis_cols], y_train, X_test[fatty_cirrhosis_cols], y_test)\n",
    "fatty_cirrhosis_mlp = model\n",
    "prediction = images_pred(y_pred)\n",
    "print(\"cirrhosis/Fatty MLP Image Accuracy: \", images_acc(y_test, prediction))\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "341e7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"normal_fatty\": (normal_fatty_mlp, normal_fatty_std, normal_fatty_cols),\n",
    "    \"normal_cirrhosis\": (normal_cirrhosis_mlp, normal_cirrhosis_std, normal_cirrhosis_cols),\n",
    "    \"fatty_cirrhosis\": (fatty_cirrhosis_mlp, fatty_cirrhosis_std, fatty_cirrhosis_cols)\n",
    "}\n",
    "\n",
    "X_test = test_data.copy()\n",
    "y_test = X_test.pop('target')\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "X_test = pd.DataFrame(std.transform(X_test), columns = X_test.columns, index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "52782718",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "predictions = {}\n",
    "for name in models.keys():\n",
    "    X_test = test_data.copy()\n",
    "    y_test = X_test.pop('target')\n",
    "    X_test = pd.DataFrame(models[name][1].transform(X_test), columns = X_test.columns, index = X_test.index)\n",
    "    X_test =  X_test[models[name][2]]\n",
    "    y_pred = pd.Series(models[name][0].predict(X_test),index=y_test.index)\n",
    "    predictions[name] = images_pred(y_pred)\n",
    "    \n",
    "image_names = np.unique(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ebd475fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = np.unique(y_test.index)\n",
    "final_pred = {}\n",
    "for image in image_name:\n",
    "    pred = {\n",
    "        'normal': 0,\n",
    "        'fatty': 0,\n",
    "        'cirrhosis': 0\n",
    "    }\n",
    "    for model in predictions.keys():\n",
    "        pred[predictions[model][image]] += 1\n",
    "    cls = max(pred, key=pred.get)\n",
    "    if pred[cls] == 1:\n",
    "        final_pred[image] = 'abstain'\n",
    "    else: final_pred[image] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2387b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7428571428571429"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_acc(y_test, final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "424c72bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "cirrhosis      1.000000  0.400000  0.571429   5.000000\n",
      "fatty          0.789474  0.937500  0.857143  16.000000\n",
      "normal         0.692308  0.692308  0.692308  13.000000\n",
      "accuracy       0.764706  0.764706  0.764706   0.764706\n",
      "macro avg      0.827260  0.676603  0.706960  34.000000\n",
      "weighted avg   0.783282  0.764706  0.752101  34.000000\n",
      "Abstention Rate:  0.02857142857142857\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test[~y_test.index.duplicated(keep='first')].sort_index()\n",
    "y_pred = pd.Series(final_pred).sort_index()\n",
    "abstain = y_pred[y_pred=='abstain'].index\n",
    "\n",
    "y_test = y_test.drop(abstain)\n",
    "y_pred = y_pred.drop(abstain)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict = True)\n",
    "cr = pd.DataFrame(report).transpose()\n",
    "print(cr)\n",
    "print(\"Abstention Rate: \", len(abstain)/(len(y_pred)+len(abstain)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5546eff9",
   "metadata": {},
   "source": [
    "from joblib import dump\n",
    "\n",
    "for name in models.keys():\n",
    "    dump(models[name][0], f'dataset/models/{name}_mlp.joblib') \n",
    "    dump(models[name][1], f'dataset/models/{name}_std.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
